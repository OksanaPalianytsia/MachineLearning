{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/\n",
    "- https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-latent-dirichlet-allocation-437c81220158\n",
    "- https://towardsdatascience.com/evaluation-of-language-models-through-perplexity-and-shannon-visualization-method-9148fbe10bd0\n",
    "- https://towardsdatascience.com/evaluate-topic-model-in-python-latent-dirichlet-allocation-lda-7d57484bb5d0\n",
    "- https://www.machinelearningplus.com/nlp/topic-modeling-visualization-how-to-present-results-lda-models/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install spacy gensim pyLDAvis\n",
    "!{sys.executable} -m spacy download en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import nltk; nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import newsgroups\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = newsgroups.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rec.sport.baseball' 'comp.sys.mac.hardware' 'sci.crypt' 'alt.atheism'\n",
      " 'comp.windows.x' 'sci.med' 'sci.electronics' 'talk.politics.mideast'\n",
      " 'rec.sport.hockey' 'misc.forsale' 'rec.autos' 'comp.os.ms-windows.misc'\n",
      " 'rec.motorcycles' 'sci.space' 'comp.graphics' 'comp.sys.ibm.pc.hardware'\n",
      " 'talk.politics.guns' 'talk.politics.misc' 'talk.religion.misc'\n",
      " 'soc.religion.christian']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>morgan and guzman will have era's 1 run higher...</td>\n",
       "      <td>rec.sport.baseball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Well, I just got my Centris 610 yesterday.  It...</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>History and classical methods. Modern methods....</td>\n",
       "      <td>sci.crypt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATTENTION: Mac Quadra owners: Many storage ind...</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>To show that the examples I and others have pr...</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                  group\n",
       "0  morgan and guzman will have era's 1 run higher...     rec.sport.baseball\n",
       "1  Well, I just got my Centris 610 yesterday.  It...  comp.sys.mac.hardware\n",
       "2  History and classical methods. Modern methods....              sci.crypt\n",
       "3  ATTENTION: Mac Quadra owners: Many storage ind...  comp.sys.mac.hardware\n",
       "4  To show that the examples I and others have pr...            alt.atheism"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.group.unique())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize words and Clean-up text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['morgan', 'and', 'guzman', 'will', 'have', 'era', 'run', 'higher', 'than', 'last', 'year', 'and', 'the', 'cubs', 'will', 'be', 'idiots', 'and', 'not', 'pitch', 'harkey', 'as', 'much', 'as', 'hibbard', 'castillo', 'won', 'be', 'good', 'think', 'he', 'stud', 'pitcher', 'this', 'season', 'so', 'far', 'morgan', 'and', 'guzman', 'helped', 'to', 'lead', 'the', 'cubs', 'at', 'top', 'in', 'era', 'even', 'better', 'than', 'the', 'rotation', 'at', 'atlanta', 'cubs', 'era', 'at', 'while', 'braves', 'at', 'we', 'know', 'it', 'is', 'early', 'in', 'the', 'season', 'we', 'cubs', 'fans', 'have', 'learned', 'how', 'to', 'enjoy', 'the', 'short', 'triumph', 'while', 'it', 'is', 'still', 'there']]\n"
     ]
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(data.text))\n",
    "\n",
    "print(data_words[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Bigram and Trigram Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['well', 'just', 'got', 'my', 'centris', 'yesterday', 'it', 'took', 'just', 'over', 'two', 'weeks', 'from', 'placing', 'the', 'order', 'the', 'dealer', 'rutgers', 'computer', 'store', 'appologized', 'because', 'apple', 'made', 'substitution', 'on', 'my', 'order', 'ordered', 'the', 'one', 'without', 'ethernet', 'but', 'they', 'substituted', 'one', 'ethernet', 'he', 'wanted', 'to', 'know', 'if', 'that', 'would', 'be', 'alright', 'with', 'me', 'they', 'must', 'be', 'backlogged', 'on', 'centri', 'out', 'ethernet', 'so', 'they', 're', 'just', 'shipping', 'them', 'with', 'anyway', 'very', 'happy', 'with', 'the', 'with', 'few', 'exceptions', 'being', 'nosy', 'decided', 'to', 'open', 'it', 'up', 'powering', 'it', 'on', 'for', 'the', 'first', 'time', 'the', 'scsi', 'cable', 'to', 'the', 'hard_drive', 'was', 'only', 'partially', 'connected', 'must', 'have', 'come', 'loose', 'in', 'shipping', 'no', 'big', 'deal', 'but', 'would', 'have', 'been', 'pissed', 'if', 'tried', 'to', 'boot', 'it', 'and', 'it', 'wouldn', 'come', 'up', 'the', 'hard_drive', 'also', 'has', 'an', 'annoying', 'high', 'pitched', 'whine', 've', 'heard', 'apple', 'will', 'exchange', 'it', 'if', 'you', 'complain', 'so', 'might', 'try', 'to', 'get', 'it', 'swapped', 'am', 'also', 'dissappionted', 'by', 'the', 'lack', 'of', 'soft', 'power', 'on', 'off', 'this', 'wasn', 'mentioned', 'in', 'any', 'of', 'the', 'literature', 'saw', 'also', 'the', 'location', 'of', 'the', 'reset', 'interupt', 'buttons', 'is', 'awful', 'having', 'keyboard', 'control', 'for', 'these', 'functions', 'was', 'much', 'more', 'convenient', 'oh', 'and', 'the', 'screen', 'seems', 'tojump', 'in', 'wierd', 'way', 'on', 'power', 'up', 've', 'seen', 'this', 'mentioned', 'by', 'others', 'so', 'it', 'must', 'be', 'feature', 'anyway', 'above', 'all', 'it', 'fast', 'great', 'machine', 'at', 'great', 'price', 'email']\n"
     ]
    }
   ],
   "source": [
    "# See trigram example\n",
    "print(trigram_mod[bigram_mod[data_words[1]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Stopwords, Make Bigrams and Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['run', 'higher', 'last', 'year', 'cub', 'idiot', 'pitch', 'harkey', 'much', 'hibbard', 'good', 'think', 'stud', 'pitcher', 'season', 'far', 'help', 'lead', 'top', 'era', 'even', 'well', 'brave', 'know', 'early', 'season', 'cub', 'fan', 'learn', 'enjoy', 'short', 'triumph', 'still']]\n"
     ]
    }
   ],
   "source": [
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Dictionary and Corpus needed for Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 2), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 2), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1)]]\n",
      "brave\n"
     ]
    }
   ],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(corpus[:1])\n",
    "print(id2word[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('brave', 1),\n",
       "  ('cub', 2),\n",
       "  ('early', 1),\n",
       "  ('enjoy', 1),\n",
       "  ('era', 1),\n",
       "  ('even', 1),\n",
       "  ('fan', 1),\n",
       "  ('far', 1),\n",
       "  ('good', 1),\n",
       "  ('harkey', 1),\n",
       "  ('help', 1),\n",
       "  ('hibbard', 1),\n",
       "  ('higher', 1),\n",
       "  ('idiot', 1),\n",
       "  ('know', 1),\n",
       "  ('last', 1),\n",
       "  ('lead', 1),\n",
       "  ('learn', 1),\n",
       "  ('much', 1),\n",
       "  ('pitch', 1),\n",
       "  ('pitcher', 1),\n",
       "  ('run', 1),\n",
       "  ('season', 2),\n",
       "  ('short', 1),\n",
       "  ('still', 1),\n",
       "  ('stud', 1),\n",
       "  ('think', 1),\n",
       "  ('top', 1),\n",
       "  ('triumph', 1),\n",
       "  ('well', 1),\n",
       "  ('year', 1)]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Human readable format of corpus (term-frequency)\n",
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Topic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha and eta are hyperparameters that affect sparsity of the topics.\n",
    "# according to the Gensim docs, both defaults to 1.0/num_topics prior.\n",
    "# chunksize is the number of documents to be used in each training chunk. \n",
    "# update_every determines how often the model parameters should be updated \n",
    "# and passes is the total number of training passes.\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=20, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.060*\"steal\" + 0.048*\"proceed\" + 0.046*\"russian\" + 0.042*\"brain\" + '\n",
      "  '0.041*\"wave\" + 0.041*\"eternal\" + 0.040*\"biblical\" + 0.034*\"damn\" + '\n",
      "  '0.026*\"tour\" + 0.023*\"righteous\"'),\n",
      " (1,\n",
      "  '0.143*\"key\" + 0.081*\"phone\" + 0.046*\"private\" + 0.041*\"encryption\" + '\n",
      "  '0.038*\"government\" + 0.035*\"security\" + 0.031*\"communication\" + '\n",
      "  '0.029*\"public\" + 0.024*\"secret\" + 0.022*\"technology\"'),\n",
      " (2,\n",
      "  '0.053*\"jewish\" + 0.050*\"book\" + 0.035*\"article\" + 0.027*\"issue\" + '\n",
      "  '0.023*\"reference\" + 0.021*\"material\" + 0.020*\"appear\" + 0.019*\"group\" + '\n",
      "  '0.017*\"relate\" + 0.016*\"meaning\"'),\n",
      " (3,\n",
      "  '0.037*\"would\" + 0.035*\"get\" + 0.035*\"email\" + 0.034*\"go\" + 0.033*\"know\" + '\n",
      "  '0.022*\"think\" + 0.019*\"see\" + 0.019*\"look\" + 0.019*\"want\" + 0.018*\"good\"'),\n",
      " (4,\n",
      "  '0.026*\"say\" + 0.024*\"people\" + 0.012*\"believe\" + 0.012*\"would\" + '\n",
      "  '0.012*\"make\" + 0.011*\"think\" + 0.010*\"mean\" + 0.010*\"may\" + 0.009*\"word\" + '\n",
      "  '0.009*\"fact\"'),\n",
      " (5,\n",
      "  '0.054*\"run\" + 0.052*\"window\" + 0.032*\"machine\" + 0.028*\"do\" + '\n",
      "  '0.028*\"display\" + 0.027*\"card\" + 0.025*\"disk\" + 0.024*\"pc\" + 0.024*\"server\" '\n",
      "  '+ 0.022*\"system\"'),\n",
      " (6,\n",
      "  '0.033*\"rubber\" + 0.000*\"probe\" + 0.000*\"spare\" + 0.000*\"stopper\" + '\n",
      "  '0.000*\"trunk\" + 0.000*\"helmet\" + 0.000*\"foam\" + 0.000*\"explosive\" + '\n",
      "  '0.000*\"engine\" + 0.000*\"plastic\"'),\n",
      " (7,\n",
      "  '0.044*\"file\" + 0.042*\"email\" + 0.029*\"program\" + 0.024*\"include\" + '\n",
      "  '0.022*\"information\" + 0.021*\"available\" + 0.018*\"send\" + 0.018*\"mail\" + '\n",
      "  '0.017*\"list\" + 0.016*\"format\"'),\n",
      " (8,\n",
      "  '0.346*\"image\" + 0.122*\"space\" + 0.043*\"launch\" + 0.040*\"surface\" + '\n",
      "  '0.025*\"observe\" + 0.023*\"art\" + 0.022*\"earth\" + 0.021*\"reader\" + '\n",
      "  '0.021*\"map\" + 0.015*\"patent\"'),\n",
      " (9,\n",
      "  '0.090*\"study\" + 0.058*\"useful\" + 0.050*\"fly\" + 0.039*\"gas\" + '\n",
      "  '0.037*\"disease\" + 0.033*\"analysis\" + 0.032*\"volume\" + 0.030*\"link\" + '\n",
      "  '0.030*\"magazine\" + 0.028*\"survey\"'),\n",
      " (10,\n",
      "  '0.058*\"use\" + 0.029*\"system\" + 0.021*\"also\" + 0.019*\"base\" + 0.016*\"new\" + '\n",
      "  '0.014*\"graphic\" + 0.014*\"work\" + 0.014*\"problem\" + 0.013*\"need\" + '\n",
      "  '0.012*\"set\"'),\n",
      " (11,\n",
      "  '0.544*\"email\" + 0.066*\"degree\" + 0.034*\"morality\" + 0.018*\"animal\" + '\n",
      "  '0.016*\"alter\" + 0.013*\"representative\" + 0.012*\"successfully\" + '\n",
      "  '0.010*\"kingdom\" + 0.007*\"max\" + 0.006*\"ax\"'),\n",
      " (12,\n",
      "  '0.188*\"child\" + 0.057*\"water\" + 0.045*\"oil\" + 0.042*\"connect\" + '\n",
      "  '0.038*\"fuel\" + 0.038*\"parent\" + 0.035*\"heat\" + 0.030*\"cable\" + 0.024*\"lock\" '\n",
      "  '+ 0.021*\"circuit\"'),\n",
      " (13,\n",
      "  '0.045*\"theory\" + 0.042*\"science\" + 0.040*\"planet\" + 0.040*\"vote\" + '\n",
      "  '0.036*\"scientific\" + 0.036*\"reaction\" + 0.031*\"active\" + 0.030*\"star\" + '\n",
      "  '0.028*\"objective\" + 0.028*\"scientist\"'),\n",
      " (14,\n",
      "  '0.131*\"car\" + 0.048*\"bike\" + 0.038*\"commercial\" + 0.035*\"mile\" + '\n",
      "  '0.034*\"temperature\" + 0.033*\"ride\" + 0.023*\"medical\" + 0.023*\"vehicle\" + '\n",
      "  '0.022*\"road\" + 0.020*\"dog\"'),\n",
      " (15,\n",
      "  '0.120*\"bit\" + 0.104*\"software\" + 0.079*\"color\" + 0.050*\"speed\" + '\n",
      "  '0.040*\"design\" + 0.031*\"battery\" + 0.027*\"device\" + 0.025*\"chip\" + '\n",
      "  '0.023*\"high\" + 0.022*\"hardware\"'),\n",
      " (16,\n",
      "  '0.256*\"drive\" + 0.116*\"driver\" + 0.058*\"compound\" + 0.041*\"apple\" + '\n",
      "  '0.039*\"scsi\" + 0.036*\"food\" + 0.031*\"hard\" + 0.016*\"blind\" + 0.016*\"boot\" + '\n",
      "  '0.015*\"angel\"'),\n",
      " (17,\n",
      "  '0.055*\"government\" + 0.042*\"kill\" + 0.032*\"fire\" + 0.031*\"gun\" + '\n",
      "  '0.022*\"country\" + 0.020*\"people\" + 0.017*\"war\" + 0.016*\"attack\" + '\n",
      "  '0.016*\"report\" + 0.015*\"land\"'),\n",
      " (18,\n",
      "  '0.087*\"solar\" + 0.074*\"ship\" + 0.060*\"shipping\" + 0.042*\"crack\" + '\n",
      "  '0.027*\"partially\" + 0.025*\"apartment\" + 0.019*\"soviet\" + 0.016*\"drill\" + '\n",
      "  '0.015*\"awful\" + 0.015*\"north\"'),\n",
      " (19,\n",
      "  '0.020*\"year\" + 0.019*\"time\" + 0.016*\"first\" + 0.014*\"may\" + 0.014*\"make\" + '\n",
      "  '0.013*\"take\" + 0.012*\"much\" + 0.012*\"day\" + 0.011*\"last\" + 0.010*\"power\"')]\n"
     ]
    }
   ],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic 0 is a represented as 0.060*\"steal\" + 0.048*\"proceed\" + 0.046*\"russian\" + 0.042*\"brain\" + 0.041*\"wave\" + 0.041*\"eternal\" + 0.040*\"biblical\" + 0.034*\"damn\" + 0.026*\"tour\" + 0.023*\"righteous\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Model Perplexity and Coherence Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -13.029781338458692\n",
      "\n",
      "Coherence Score:  0.42639399693627017\n"
     ]
    }
   ],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the topics-keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each bubble on the left-hand side plot represents a topic. The larger the bubble, the more prevalent is that topic.\n",
    "\n",
    "A good topic model will have fairly big, non-overlapping bubbles scattered throughout the chart instead of being clustered in one quadrant.\n",
    "\n",
    "A model with too many topics, will typically have many overlaps, small sized bubbles clustered in one region of the chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pyLDAvis.enable_notebook()\n",
    "#vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "#vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA Mallet model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the contents of the mallet folder to C:/mallet (or some other path, just put the correct reference below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(13,\n",
      "  [('good', 0.04738789080181685),\n",
      "   ('thing', 0.04184681661385737),\n",
      "   ('time', 0.02598841837451418),\n",
      "   ('bad', 0.02350664148469571),\n",
      "   ('hear', 0.021664819641937345),\n",
      "   ('post', 0.02158677634351538),\n",
      "   ('make', 0.02013517099286684),\n",
      "   ('read', 0.018636739663165123),\n",
      "   ('find', 0.018340175129161657),\n",
      "   ('lot', 0.0178094806998923)]),\n",
      " (15,\n",
      "  [('claim', 0.01890079784677497),\n",
      "   ('people', 0.01820388349514563),\n",
      "   ('question', 0.01727866961453427),\n",
      "   ('reason', 0.015764683264442948),\n",
      "   ('true', 0.015272036912429107),\n",
      "   ('exist', 0.014707295972315678),\n",
      "   ('argument', 0.013746034797654523),\n",
      "   ('religion', 0.012676631740843988),\n",
      "   ('evidence', 0.012135922330097087),\n",
      "   ('make', 0.011487071037200808)]),\n",
      " (9,\n",
      "  [('key', 0.04109776311967053),\n",
      "   ('bit', 0.021565645345956015),\n",
      "   ('system', 0.020369452656402193),\n",
      "   ('phone', 0.018865667560963105),\n",
      "   ('chip', 0.017720740272390165),\n",
      "   ('encryption', 0.01329482732104103),\n",
      "   ('call', 0.012098634631487208),\n",
      "   ('message', 0.011585980621678428),\n",
      "   ('make', 0.010423964866111862),\n",
      "   ('security', 0.00885182590269827)]),\n",
      " (10,\n",
      "  [('drug', 0.01146752961136071),\n",
      "   ('effect', 0.009079770021049986),\n",
      "   ('patient', 0.008844135850953533),\n",
      "   ('doctor', 0.00881271796160734),\n",
      "   ('problem', 0.00881271796160734),\n",
      "   ('study', 0.00860850168085708),\n",
      "   ('food', 0.007618838166451977),\n",
      "   ('treatment', 0.007618838166451977),\n",
      "   ('test', 0.007336077162336235),\n",
      "   ('medical', 0.006582047818027585)]),\n",
      " (18,\n",
      "  [('car', 0.041630403249202204),\n",
      "   ('buy', 0.015810850014505367),\n",
      "   ('bike', 0.014827708474357734),\n",
      "   ('sell', 0.012039454598201334),\n",
      "   ('engine', 0.010927376462624504),\n",
      "   ('ride', 0.01058891789962286),\n",
      "   ('price', 0.010202108113335268),\n",
      "   ('turn', 0.008654868968184895),\n",
      "   ('drive', 0.0083969957773265),\n",
      "   ('front', 0.007446088386036167)]),\n",
      " (6,\n",
      "  [('make', 0.03882100252517923),\n",
      "   ('work', 0.025411430064145358),\n",
      "   ('people', 0.025396917539836878),\n",
      "   ('time', 0.01824224305575712),\n",
      "   ('money', 0.017864917423736686),\n",
      "   ('pay', 0.01756015441325864),\n",
      "   ('year', 0.015833164020549736),\n",
      "   ('job', 0.01430934896815952),\n",
      "   ('good', 0.013583722752735611),\n",
      "   ('thing', 0.01326444721794909)]),\n",
      " (19,\n",
      "  [('mail', 0.028570597728891926),\n",
      "   ('list', 0.026011602716024252),\n",
      "   ('post', 0.025619029617459325),\n",
      "   ('send', 0.02556087063989415),\n",
      "   ('include', 0.017215057359291623),\n",
      "   ('address', 0.016211814996292366),\n",
      "   ('book', 0.015935559852857786),\n",
      "   ('information', 0.015877400875292613),\n",
      "   ('email', 0.015266731610858281),\n",
      "   ('group', 0.01336202509559882)]),\n",
      " (11,\n",
      "  [('file', 0.031478423659826886),\n",
      "   ('image', 0.023674551172158477),\n",
      "   ('window', 0.01863674130478224),\n",
      "   ('program', 0.017921561615885404),\n",
      "   ('version', 0.01516601634395936),\n",
      "   ('application', 0.01386186514655925),\n",
      "   ('display', 0.013535827347209222),\n",
      "   ('color', 0.01207391592431716),\n",
      "   ('server', 0.011516496460912275),\n",
      "   ('software', 0.011411322977250976)]),\n",
      " (2,\n",
      "  [('people', 0.02873444126707834),\n",
      "   ('gun', 0.023954577479381657),\n",
      "   ('law', 0.020749582107284458),\n",
      "   ('government', 0.019616782018870793),\n",
      "   ('state', 0.016978186690980425),\n",
      "   ('case', 0.010112312984375647),\n",
      "   ('crime', 0.009587356845842486),\n",
      "   ('make', 0.00943539585837236),\n",
      "   ('weapon', 0.009007142166411096),\n",
      "   ('person', 0.008136820147264011)]),\n",
      " (12,\n",
      "  [('find', 0.01599025593778791),\n",
      "   ('show', 0.01419447524164962),\n",
      "   ('man', 0.012336232608254345),\n",
      "   ('number', 0.011165071284685895),\n",
      "   ('science', 0.009634753821889787),\n",
      "   ('homosexual', 0.009431752525804587),\n",
      "   ('theory', 0.009369290588547604),\n",
      "   ('time', 0.008588516372835303),\n",
      "   ('point', 0.008307437655178876),\n",
      "   ('source', 0.00793266603163697)])]\n",
      "\n",
      "Coherence Score:  0.5444219656260233\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from gensim.models.wrappers import LdaMallet\n",
    "os.environ.update({'MALLET_HOME':r'C:/mallet/'})\n",
    "\n",
    "mallet_path = 'C:/mallet/bin/mallet' # update this path\n",
    "\n",
    "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=20, id2word=id2word)\n",
    "\n",
    "# Show Topics\n",
    "pprint(ldamallet.show_topics(formatted=False))\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_ldamallet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can take a long time to run.\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=data_lemmatized, start=10, limit=40, step=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show graph\n",
    "limit=40; start=10; step=10;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Topics = 10  has Coherence Value of 0.5076\n",
      "Num Topics = 20  has Coherence Value of 0.557\n",
      "Num Topics = 30  has Coherence Value of 0.5509\n"
     ]
    }
   ],
   "source": [
    "# Print the coherence scores\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.032*\"post\" + 0.025*\"send\" + 0.023*\"mail\" + 0.022*\"book\" + '\n",
      "  '0.022*\"information\" + 0.021*\"list\" + 0.020*\"group\" + 0.017*\"article\" + '\n",
      "  '0.017*\"address\" + 0.015*\"include\"'),\n",
      " (1,\n",
      "  '0.040*\"game\" + 0.031*\"year\" + 0.028*\"team\" + 0.028*\"play\" + 0.021*\"player\" '\n",
      "  '+ 0.016*\"win\" + 0.016*\"good\" + 0.012*\"hit\" + 0.011*\"season\" + 0.011*\"fan\"'),\n",
      " (2,\n",
      "  '0.016*\"time\" + 0.015*\"day\" + 0.014*\"people\" + 0.013*\"start\" + '\n",
      "  '0.013*\"happen\" + 0.013*\"leave\" + 0.011*\"hear\" + 0.011*\"woman\" + '\n",
      "  '0.011*\"child\" + 0.010*\"call\"'),\n",
      " (3,\n",
      "  '0.472*\"email\" + 0.134*\"ax\" + 0.100*\"max\" + 0.010*\"advance\" + 0.008*\"ca\" + '\n",
      "  '0.006*\"info\" + 0.006*\"interested\" + 0.005*\"mail\" + 0.005*\"picture\" + '\n",
      "  '0.005*\"reply\"'),\n",
      " (4,\n",
      "  '0.016*\"bike\" + 0.015*\"back\" + 0.013*\"leave\" + 0.011*\"ride\" + 0.011*\"turn\" + '\n",
      "  '0.011*\"side\" + 0.010*\"time\" + 0.009*\"front\" + 0.009*\"hand\" + 0.008*\"good\"'),\n",
      " (5,\n",
      "  '0.014*\"claim\" + 0.014*\"exist\" + 0.013*\"argument\" + 0.012*\"evidence\" + '\n",
      "  '0.011*\"religion\" + 0.011*\"reason\" + 0.010*\"true\" + 0.009*\"word\" + '\n",
      "  '0.009*\"belief\" + 0.009*\"people\"'),\n",
      " (6,\n",
      "  '0.013*\"love\" + 0.013*\"word\" + 0.011*\"church\" + 0.010*\"christian\" + '\n",
      "  '0.010*\"man\" + 0.010*\"life\" + 0.009*\"sin\" + 0.008*\"faith\" + 0.008*\"give\" + '\n",
      "  '0.007*\"speak\"'),\n",
      " (7,\n",
      "  '0.056*\"time\" + 0.050*\"problem\" + 0.040*\"question\" + 0.035*\"find\" + '\n",
      "  '0.027*\"make\" + 0.026*\"point\" + 0.026*\"work\" + 0.021*\"give\" + 0.017*\"answer\" '\n",
      "  '+ 0.017*\"thing\"'),\n",
      " (8,\n",
      "  '0.057*\"people\" + 0.043*\"thing\" + 0.035*\"make\" + 0.030*\"good\" + 0.021*\"bad\" '\n",
      "  '+ 0.017*\"read\" + 0.015*\"opinion\" + 0.015*\"feel\" + 0.014*\"talk\" + '\n",
      "  '0.013*\"real\"'),\n",
      " (9,\n",
      "  '0.029*\"buy\" + 0.027*\"price\" + 0.026*\"sell\" + 0.022*\"cost\" + 0.021*\"pay\" + '\n",
      "  '0.021*\"good\" + 0.016*\"money\" + 0.015*\"make\" + 0.013*\"sale\" + 0.013*\"offer\"'),\n",
      " (10,\n",
      "  '0.015*\"people\" + 0.011*\"war\" + 0.010*\"jewish\" + 0.010*\"kill\" + '\n",
      "  '0.009*\"attack\" + 0.009*\"israeli\" + 0.008*\"government\" + 0.008*\"armenian\" + '\n",
      "  '0.008*\"country\" + 0.008*\"turkish\"'),\n",
      " (11,\n",
      "  '0.029*\"image\" + 0.018*\"file\" + 0.016*\"software\" + 0.016*\"color\" + '\n",
      "  '0.014*\"version\" + 0.014*\"program\" + 0.013*\"bit\" + 0.013*\"graphic\" + '\n",
      "  '0.012*\"format\" + 0.011*\"package\"'),\n",
      " (12,\n",
      "  '0.024*\"gun\" + 0.021*\"law\" + 0.018*\"people\" + 0.016*\"state\" + 0.015*\"fire\" + '\n",
      "  '0.013*\"government\" + 0.011*\"kill\" + 0.010*\"case\" + 0.010*\"crime\" + '\n",
      "  '0.009*\"death\"'),\n",
      " (13,\n",
      "  '0.019*\"space\" + 0.011*\"system\" + 0.010*\"launch\" + 0.008*\"design\" + '\n",
      "  '0.007*\"earth\" + 0.007*\"orbit\" + 0.007*\"mission\" + 0.007*\"project\" + '\n",
      "  '0.007*\"large\" + 0.006*\"year\"'),\n",
      " (14,\n",
      "  '0.038*\"key\" + 0.018*\"system\" + 0.018*\"phone\" + 0.015*\"bit\" + 0.014*\"chip\" + '\n",
      "  '0.012*\"government\" + 0.012*\"encryption\" + 0.010*\"security\" + 0.010*\"public\" '\n",
      "  '+ 0.009*\"technology\"'),\n",
      " (15,\n",
      "  '0.042*\"car\" + 0.016*\"power\" + 0.012*\"engine\" + 0.011*\"light\" + '\n",
      "  '0.010*\"sound\" + 0.009*\"high\" + 0.009*\"low\" + 0.008*\"ground\" + '\n",
      "  '0.008*\"battery\" + 0.007*\"wire\"'),\n",
      " (16,\n",
      "  '0.015*\"make\" + 0.011*\"work\" + 0.010*\"government\" + 0.010*\"year\" + '\n",
      "  '0.010*\"people\" + 0.009*\"job\" + 0.008*\"support\" + 0.007*\"decision\" + '\n",
      "  '0.007*\"vote\" + 0.007*\"plan\"'),\n",
      " (17,\n",
      "  '0.013*\"drug\" + 0.012*\"study\" + 0.009*\"effect\" + 0.009*\"patient\" + '\n",
      "  '0.008*\"doctor\" + 0.008*\"test\" + 0.007*\"treatment\" + 0.007*\"food\" + '\n",
      "  '0.006*\"medical\" + 0.006*\"eat\"'),\n",
      " (18,\n",
      "  '0.039*\"file\" + 0.032*\"window\" + 0.022*\"program\" + 0.016*\"application\" + '\n",
      "  '0.014*\"set\" + 0.014*\"run\" + 0.013*\"server\" + 0.011*\"include\" + '\n",
      "  '0.011*\"email\" + 0.010*\"line\"'),\n",
      " (19,\n",
      "  '0.041*\"drive\" + 0.027*\"card\" + 0.026*\"system\" + 0.020*\"run\" + 0.020*\"work\" '\n",
      "  '+ 0.020*\"driver\" + 0.017*\"disk\" + 0.015*\"problem\" + 0.015*\"machine\" + '\n",
      "  '0.014*\"monitor\"')]\n"
     ]
    }
   ],
   "source": [
    "# Select the model and print the topics\n",
    "optimal_model = model_list[1]\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "pprint(optimal_model.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the dominant topic in each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2530</td>\n",
       "      <td>game, year, team, play, player, win, good, hit...</td>\n",
       "      <td>morgan and guzman will have era's 1 run higher...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.1923</td>\n",
       "      <td>drive, card, system, run, work, driver, disk, ...</td>\n",
       "      <td>Well, I just got my Centris 610 yesterday.  It...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.3795</td>\n",
       "      <td>key, system, phone, bit, chip, government, enc...</td>\n",
       "      <td>History and classical methods. Modern methods....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.2706</td>\n",
       "      <td>drive, card, system, run, work, driver, disk, ...</td>\n",
       "      <td>ATTENTION: Mac Quadra owners: Many storage ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1941</td>\n",
       "      <td>claim, exist, argument, evidence, religion, re...</td>\n",
       "      <td>To show that the examples I and others have pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.1460</td>\n",
       "      <td>drive, card, system, run, work, driver, disk, ...</td>\n",
       "      <td>Help!!! I have an ADB graphicsd tablet which I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.1817</td>\n",
       "      <td>file, window, program, application, set, run, ...</td>\n",
       "      <td>Hello world, I want to write my Xt-application...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.3040</td>\n",
       "      <td>file, window, program, application, set, run, ...</td>\n",
       "      <td>&lt;email&gt;    Hi.   &gt;     I use Emacs and I want ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.1043</td>\n",
       "      <td>time, problem, question, find, make, point, wo...</td>\n",
       "      <td>Does anyone on this newsgroup happen to know W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.1744</td>\n",
       "      <td>car, power, engine, light, sound, high, low, g...</td>\n",
       "      <td>X-Posted-From: britain.madvlsi.columbia.edu Hi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0            0             1.0              0.2530   \n",
       "1            1            19.0              0.1923   \n",
       "2            2            14.0              0.3795   \n",
       "3            3            19.0              0.2706   \n",
       "4            4             5.0              0.1941   \n",
       "5            5            19.0              0.1460   \n",
       "6            6            18.0              0.1817   \n",
       "7            7            18.0              0.3040   \n",
       "8            8             7.0              0.1043   \n",
       "9            9            15.0              0.1744   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  game, year, team, play, player, win, good, hit...   \n",
       "1  drive, card, system, run, work, driver, disk, ...   \n",
       "2  key, system, phone, bit, chip, government, enc...   \n",
       "3  drive, card, system, run, work, driver, disk, ...   \n",
       "4  claim, exist, argument, evidence, religion, re...   \n",
       "5  drive, card, system, run, work, driver, disk, ...   \n",
       "6  file, window, program, application, set, run, ...   \n",
       "7  file, window, program, application, set, run, ...   \n",
       "8  time, problem, question, find, make, point, wo...   \n",
       "9  car, power, engine, light, sound, high, low, g...   \n",
       "\n",
       "                                                Text  \n",
       "0  morgan and guzman will have era's 1 run higher...  \n",
       "1  Well, I just got my Centris 610 yesterday.  It...  \n",
       "2  History and classical methods. Modern methods....  \n",
       "3  ATTENTION: Mac Quadra owners: Many storage ind...  \n",
       "4  To show that the examples I and others have pr...  \n",
       "5  Help!!! I have an ADB graphicsd tablet which I...  \n",
       "6  Hello world, I want to write my Xt-application...  \n",
       "7  <email>    Hi.   >     I use Emacs and I want ...  \n",
       "8  Does anyone on this newsgroup happen to know W...  \n",
       "9  X-Posted-From: britain.madvlsi.columbia.edu Hi...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=data):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=corpus, texts=data.text)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "\n",
    "# Show\n",
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - model: 0.4771641494986901\n",
      "1 - model: 0.4771641494986901\n",
      "2 - model: 0.4771641494986901\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import v_measure_score\n",
    "for i, model in enumerate(model_list):\n",
    "    df = format_topics_sentences(ldamodel=model, corpus=corpus, texts=data.text)\n",
    "    df = df.reset_index()\n",
    "    df.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "    print(f'{i} - model: {v_measure_score(data.group, df.Dominant_Topic)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the most representative document for each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group top 5 sentences under each topic\n",
    "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
    "\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=[0]).head(1)], \n",
    "                                            axis=0)\n",
    "\n",
    "# Reset Index    \n",
    "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Format\n",
    "sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Text\"]\n",
    "\n",
    "# Show\n",
    "sent_topics_sorteddf_mallet.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic distribution across documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1047</td>\n",
       "      <td>post, send, mail, book, information, list, gro...</td>\n",
       "      <td>0.0556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1747</td>\n",
       "      <td>game, year, team, play, player, win, good, hit...</td>\n",
       "      <td>0.0927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>434</td>\n",
       "      <td>time, day, people, start, happen, leave, hear,...</td>\n",
       "      <td>0.0230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>492</td>\n",
       "      <td>email, ax, max, advance, ca, info, interested,...</td>\n",
       "      <td>0.0261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1043</td>\n",
       "      <td>bike, back, leave, ride, turn, side, time, fro...</td>\n",
       "      <td>0.0553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>907</td>\n",
       "      <td>claim, exist, argument, evidence, religion, re...</td>\n",
       "      <td>0.0481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1071</td>\n",
       "      <td>love, word, church, christian, man, life, sin,...</td>\n",
       "      <td>0.0568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>308</td>\n",
       "      <td>time, problem, question, find, make, point, wo...</td>\n",
       "      <td>0.0163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>623</td>\n",
       "      <td>people, thing, make, good, bad, read, opinion,...</td>\n",
       "      <td>0.0331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1071</td>\n",
       "      <td>buy, price, sell, cost, pay, good, money, make...</td>\n",
       "      <td>0.0568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.0</td>\n",
       "      <td>798</td>\n",
       "      <td>people, war, jewish, kill, attack, israeli, go...</td>\n",
       "      <td>0.0423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11.0</td>\n",
       "      <td>891</td>\n",
       "      <td>image, file, software, color, version, program...</td>\n",
       "      <td>0.0473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1071</td>\n",
       "      <td>gun, law, people, state, fire, government, kil...</td>\n",
       "      <td>0.0568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13.0</td>\n",
       "      <td>800</td>\n",
       "      <td>space, system, launch, design, earth, orbit, m...</td>\n",
       "      <td>0.0424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14.0</td>\n",
       "      <td>812</td>\n",
       "      <td>key, system, phone, bit, chip, government, enc...</td>\n",
       "      <td>0.0431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1240</td>\n",
       "      <td>car, power, engine, light, sound, high, low, g...</td>\n",
       "      <td>0.0658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16.0</td>\n",
       "      <td>454</td>\n",
       "      <td>make, work, government, year, people, job, sup...</td>\n",
       "      <td>0.0241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17.0</td>\n",
       "      <td>816</td>\n",
       "      <td>drug, study, effect, patient, doctor, test, tr...</td>\n",
       "      <td>0.0433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18.0</td>\n",
       "      <td>1153</td>\n",
       "      <td>file, window, program, application, set, run, ...</td>\n",
       "      <td>0.0612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19.0</td>\n",
       "      <td>2068</td>\n",
       "      <td>drive, card, system, run, work, driver, disk, ...</td>\n",
       "      <td>0.1097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Dominant_Topic  Count                                           Keywords  \\\n",
       "0              0.0   1047  post, send, mail, book, information, list, gro...   \n",
       "1              1.0   1747  game, year, team, play, player, win, good, hit...   \n",
       "2              2.0    434  time, day, people, start, happen, leave, hear,...   \n",
       "3              3.0    492  email, ax, max, advance, ca, info, interested,...   \n",
       "4              4.0   1043  bike, back, leave, ride, turn, side, time, fro...   \n",
       "5              5.0    907  claim, exist, argument, evidence, religion, re...   \n",
       "6              6.0   1071  love, word, church, christian, man, life, sin,...   \n",
       "7              7.0    308  time, problem, question, find, make, point, wo...   \n",
       "8              8.0    623  people, thing, make, good, bad, read, opinion,...   \n",
       "9              9.0   1071  buy, price, sell, cost, pay, good, money, make...   \n",
       "10            10.0    798  people, war, jewish, kill, attack, israeli, go...   \n",
       "11            11.0    891  image, file, software, color, version, program...   \n",
       "12            12.0   1071  gun, law, people, state, fire, government, kil...   \n",
       "13            13.0    800  space, system, launch, design, earth, orbit, m...   \n",
       "14            14.0    812  key, system, phone, bit, chip, government, enc...   \n",
       "15            15.0   1240  car, power, engine, light, sound, high, low, g...   \n",
       "16            16.0    454  make, work, government, year, people, job, sup...   \n",
       "17            17.0    816  drug, study, effect, patient, doctor, test, tr...   \n",
       "18            18.0   1153  file, window, program, application, set, run, ...   \n",
       "19            19.0   2068  drive, card, system, run, work, driver, disk, ...   \n",
       "\n",
       "    Percentage  \n",
       "0       0.0556  \n",
       "1       0.0927  \n",
       "2       0.0230  \n",
       "3       0.0261  \n",
       "4       0.0553  \n",
       "5       0.0481  \n",
       "6       0.0568  \n",
       "7       0.0163  \n",
       "8       0.0331  \n",
       "9       0.0568  \n",
       "10      0.0423  \n",
       "11      0.0473  \n",
       "12      0.0568  \n",
       "13      0.0424  \n",
       "14      0.0431  \n",
       "15      0.0658  \n",
       "16      0.0241  \n",
       "17      0.0433  \n",
       "18      0.0612  \n",
       "19      0.1097  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg = df_dominant_topic.groupby(['Dominant_Topic']).agg({'Document_No':'count', 'Keywords': 'first'}).reset_index()\n",
    "agg.rename(columns = {'Document_No':'Count'}, inplace = True)\n",
    "agg['Percentage'] = round(agg.Count / agg.Count.sum(), 4)\n",
    "agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
