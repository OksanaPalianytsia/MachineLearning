{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import sklearn.linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeuralNet class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet:\n",
    "    \"\"\"\n",
    "    NN for binary classification\n",
    "    Attributes:\n",
    "    ...\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, layers_d, normalize = True, learning_rate = 0.01, num_iter = 30000, epsilon = (10)^(-10), k = 500):\n",
    "        self.layers_d = layers_d # тут лише приховані шари а 0-го та останнього (з одним нейроном) немає\n",
    "        self.L = len(self.layers_d) + 1 # кількість шарів нейронів в мережі без урахування вихідного\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_iter = num_iter\n",
    "        self.normalize = normalize\n",
    "        self.epsilon = epsilon\n",
    "        self.k = k\n",
    "    \n",
    "    def __normalize(self, X, mean = None, std = None):\n",
    "        \"\"\"\n",
    "        Зверніть увагу, що нормалізація вхідних даних є дуже важливою для швидкодії нейронних мереж.\n",
    "        \"\"\"\n",
    "        '''\n",
    "        X.shape =  (n, m)\n",
    "        '''\n",
    "        n = X.shape[0]\n",
    "        m = mean\n",
    "        if m is None:\n",
    "            m = np.mean(X, axis=1).reshape((n, 1))\n",
    "            '''\n",
    "            m.shape =  (n, 1)\n",
    "            '''\n",
    "        s = std\n",
    "        if s is None:\n",
    "            s = np.std(X, axis=1).reshape((n, 1))\n",
    "            '''\n",
    "            s.shape =  (n, 1)\n",
    "            '''\n",
    "        X_new = (X - m) / s\n",
    "        return X_new, m, s\n",
    "\n",
    "    def __sigmoid(self, Z):\n",
    "        \"\"\"\n",
    "        В наступних практичних потрібно буде додати підтримку й інших активаційних функцій - це один з гіперпараметрів. \n",
    "        Їх можна вибирати для всіх шарів одночасно або мати різні активаційні функції на кожному з них.\n",
    "        \"\"\"\n",
    "        return 1 / (1 + np.exp(-Z))\n",
    "    \n",
    "    def __softmax(self, Z):\n",
    "        \n",
    "        x = np.exp(Z)        \n",
    "        '''\n",
    "        Z_i.shape  = (n_l, 1)\n",
    "        x.shape = (n_l, 1)\n",
    "        '''\n",
    "        return x / np.sum(x, axis=0, keepdims = True)\n",
    "    \n",
    "    def __initialize_parameters(self):\n",
    "        \n",
    "        self.parameters = {} # стоврюємо словник зі значеннями W_i та b_i,ключами в якому будуть назви W_1, w_2, ... та b_1, b_2 і т.д\n",
    "        \n",
    "        for i in range(1, self.L + 1):\n",
    "            self.parameters['W_' + str(i)] = np.random.randn(self.layers_d[i], self.layers_d[i - 1])* np.sqrt(2/self.layers_d[i - 1])\n",
    "            '''\n",
    "            W_i.shape  = (n_l, n_l-1) # (кількість нейронів на поточному шарі, кількість на попередньому)\n",
    "            '''\n",
    "            self.parameters['b_' + str(i)] = np.zeros((self.layers_d[i],1))\n",
    "            '''\n",
    "            b_i.shape  = (n_l,1) # (кількість нейронів на поточному шарі, 1)\n",
    "            '''\n",
    "       \n",
    "    def __forward_propagation(self, X):\n",
    "        \n",
    "        cache = {} # стоврюємо словник зі значеннями Z_i та A_i,ключами в якому будуть назви A_0, A_1, A_2, ... та Z_1, Z_2 і т.д\n",
    "        cache['A_0'] = X\n",
    "        \n",
    "        for i in range(1, self.L):\n",
    "            cache['Z_' + str(i)] = np.dot(self.parameters['W_' + str(i)], cache['A_' + str(i - 1)]) + self.parameters['b_' + str(i)]\n",
    "            '''\n",
    "            Z_i.shape  = (n_l, 1) = (n_l, n_l-1) * (n_l-1, 1) + (n_l,1)\n",
    "            '''\n",
    "            cache['A_' + str(i)] = self.__sigmoid(cache['Z_' + str(i)])\n",
    "            '''\n",
    "            A_i.shape  = (n_l, 1) = (n_l, 1)\n",
    "            '''       \n",
    "        cache['Z_' + str(self.L)] = np.dot(self.parameters['W_' + str(self.L)], cache['A_' + str(self.L - 1)]) + self.parameters['b_' + str(self.L)]\n",
    "        cache['A_' + str(self.L)] = self.__softmax(cache['Z_' + str(self.L)])\n",
    "        '''\n",
    "        функція softmax на останньому кроці \n",
    "        ''' \n",
    "        return cache['A_' + str(self.L)], cache\n",
    "    \n",
    "    def compute_cost(self, A, Y):\n",
    "        m = Y.shape[1]\n",
    "        res = Y * np.log(A) + (1 - Y) * np.log(1 - A)\n",
    "        J = -(1 / m) * np.sum(res)\n",
    "        '''\n",
    "        J.shape  = sum((1, m) x (1, m) - (1, m) x (1, m)) = sum((1, m)) = (1, 1)\n",
    "        '''\n",
    "        return J\n",
    "        \n",
    "    def __backward_propagation(self, X, Y, cache):\n",
    "        \n",
    "        m = X.shape[1]\n",
    "        gradients = {}\n",
    "        \n",
    "        gradients['dZ_' + str(self.L)] = cache['A_' + str(self.L)] - Y\n",
    "        '''\n",
    "        dZ_L.shape  = (1, m) - (1, m) = (1, m)\n",
    "        '''\n",
    "        gradients['dW_' + str(self.L)] = (1/m) * np.dot (gradients['dZ_' + str(self.L)], cache['A_' + str(self.L - 1)].T)\n",
    "        '''\n",
    "        dW_L.shape  = (1, m) * ((n_l-1, m).T) = (1, m) * (m, n_l-1) = (1, n_l-1)\n",
    "        '''\n",
    "        gradients['db_' + str(self.L)] = (1/m) * np.sum(gradients['dZ_' + str(self.L)], axis = 1, keepdims = True)\n",
    "        '''\n",
    "        db_L.shape  = sum((1, m)) = (1, 1)\n",
    "        '''\n",
    "        \n",
    "        for i in range(self.L - 1, 0, -1):\n",
    "            dA_i = np.dot (self.parameters['W_' + str(i + 1)].T, gradients['dZ_' + str(i + 1)])\n",
    "            '''\n",
    "            dA_i.shape  = (n_l-1, n_l)*(n_l, m) = (n_l-1, m)\n",
    "            '''\n",
    "            gradients['dZ_' + str(i)] = np.multiply(dA_i, cache['A_' + str(i)] * (1 - cache['A_' + str(i)]))\n",
    "            '''\n",
    "            dZ_i.shape  = (n_l, m)x(n_l, m) = (n_l, m)\n",
    "            '''\n",
    "            gradients['dW_' + str(i)] = (1/m) * np.dot (gradients['dZ_' + str(i)], cache['A_' + str(i - 1)].T)\n",
    "            '''\n",
    "            dW_i.shape  = (n_l, m)*((n_l-1, n).T) = (n_l, m)*(m, n_l-1) = (n_l, n_l-1)\n",
    "            '''\n",
    "            gradients['db_' + str(i)] = (1/m) * np.sum(gradients['dZ_' + str(i)], axis = 1, keepdims = True)\n",
    "            '''\n",
    "            db_i.shape = sum((n_l, m)) = (n_l, 1)\n",
    "            '''       \n",
    "        \n",
    "        return gradients\n",
    "    \n",
    "    def __update_parameters(self, gradients):\n",
    "        \n",
    "        for i in range(1, self.L + 1):\n",
    "            self.parameters['W_' + str(i)] -= self.learning_rate * gradients['dW_' + str(i)]\n",
    "            '''\n",
    "            W_i.shape  = (n_l, n_l-1) # (кількість нейронів на поточному шарі, кількість на попередньому)\n",
    "            '''\n",
    "            self.parameters['b_' + str(i)] -= self.learning_rate * gradients['db_' + str(i)]\n",
    "            '''\n",
    "            b_i.shape  = (n_l,1) # (кількість нейронів на поточному шарі, 1)\n",
    "            '''\n",
    "\n",
    "        \n",
    "    def fit(self, X_vert, Y_vert, print_cost = True):\n",
    "        \n",
    "        X= X_vert.T\n",
    "        \n",
    "        n_x = X.shape[0] # визначаємо кількість нейронів у вихідному шарі\n",
    "                \n",
    "        lb = LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False) \n",
    "        # задаємо перетворення приналежності до класів як 0 і 1 відвідно для кожного прикладу \n",
    "        #([0, 0, 1] - приклад з класу 2, [1, 0, 0] - приклад з класу 0, [0, 1, 0] - приклад з класу 1)\n",
    "        lb.fit(Y_vert)\n",
    "        \n",
    "        Y = lb.transform(Y_vert).T        \n",
    "        final_classes = Y.shape[0] # визначаємо кількість нейронів у вихідному шарі\n",
    "        \n",
    "        self.layers_d.insert(0, n_x)\n",
    "        self.layers_d.append(final_classes) \n",
    "        '''\n",
    "        додаємо вхідний та вихідний шари до прихованих \n",
    "        і отримуємо клькість всіх шарів нейронної мережі і кількість нейронів на кожному шарі\n",
    "        '''\n",
    "        \n",
    "        if self.normalize:\n",
    "            X, self.__mean, self.__std = self.__normalize(X)\n",
    "        \n",
    "        costs = []\n",
    "        \n",
    "        m = X.shape[1]\n",
    "        n_x = X.shape[0]\n",
    "        \n",
    "        self.__initialize_parameters()\n",
    "        \n",
    "        previous_cost = 0;\n",
    "\n",
    "        for i in range(self.num_iter):\n",
    "            \n",
    "            A, cache = self.__forward_propagation(X)\n",
    "\n",
    "            cost = self.compute_cost(A, Y)\n",
    "\n",
    "            gradients = self.__backward_propagation(X, Y, cache)\n",
    "\n",
    "            self.__update_parameters(gradients)\n",
    "\n",
    "            if print_cost and i % 1000 == 0:\n",
    "                print(\"{}-th iteration: {}\".format(i, cost))\n",
    "\n",
    "            if i % 1000 == 0:\n",
    "                costs.append(cost)\n",
    "            if (abs(previous_cost - cost) < self.epsilon):\n",
    "                k = k - 1\n",
    "                if (k == 0):\n",
    "                    break;\n",
    "\n",
    "        if print_cost:\n",
    "            plt.plot(costs)\n",
    "            plt.ylabel(\"Cost\")\n",
    "            plt.xlabel(\"Iteration, *1000\")\n",
    "            plt.show()\n",
    "    \n",
    "    def predict_proba(self, X_vert):\n",
    "        X = X_vert.T\n",
    "        if self.normalize:\n",
    "            X, _, _ = self.__normalize(X, self.__mean, self.__std)    \n",
    "        \n",
    "        probs = self.__forward_propagation(X)[0]\n",
    "        return probs.T\n",
    "    \n",
    "    def predict(self, X_vert):\n",
    "        probs = self.predict_proba(X_vert)\n",
    "        results_bin = (probs == probs.max(axis=1)[:, None]).astype(int)\n",
    "        '''\n",
    "        максимальне значення в кожному рядку перетворюємо на 1 а інші задаємо як 0\n",
    "        наприклад, \n",
    "        a = np.array([[0, 1], [2, 2], [4, 3]])\n",
    "        (a == a.max(axis=1)[:,None]).astype(int)\n",
    "        \n",
    "        Результат : \n",
    "        array([[0, 1], [1, 1], [1, 0]])\n",
    "        '''\n",
    "        return results_bin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "X, Y = load_iris(return_X_y = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "lb = LabelBinarizer(sparse_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = lb.fit(Y) # перетворюємо значення Y масив значеннь з 0 та 1, де 1 - приналежність до відповідного по порядку класу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb.transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = NeuralNet([4, 3, 3],normalize = True, learning_rate = 0.05, num_iter = 10000, epsilon = (10)^(-15), k = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-th iteration: 1.928717242763642\n",
      "1000-th iteration: 1.8596952067359098\n",
      "2000-th iteration: 1.1543366779064654\n",
      "3000-th iteration: 0.7281202201135801\n",
      "4000-th iteration: 0.5043201302796873\n",
      "5000-th iteration: 0.36304671767052527\n",
      "6000-th iteration: 0.2745342178902274\n",
      "7000-th iteration: 0.21953862824664747\n",
      "8000-th iteration: 0.18305216482930592\n",
      "9000-th iteration: 0.15739894751118821\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cls.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_1 \t (4, 4) \t \n",
      " [[-0.00900353  0.78558801 -1.03571892 -0.36611324]\n",
      " [-1.23274094 -0.94578127 -0.71112294 -0.45059395]\n",
      " [ 0.65907452 -0.04916282 -1.583356   -2.08406755]\n",
      " [ 0.21696073 -1.29669754  1.26085422  0.36376548]] \n",
      "b_1 \t (4, 1) \t \n",
      " [[-0.06618194]\n",
      " [ 0.95353266]\n",
      " [ 1.97554005]\n",
      " [ 0.32244871]] \n",
      "W_2 \t (3, 4) \t \n",
      " [[-1.69187837 -0.04139963 -2.50533526  2.82156845]\n",
      " [-1.03836074 -0.10443801 -0.75436396  0.29440802]\n",
      " [ 1.01985034  1.03460056  3.00028086 -2.02979887]] \n",
      "b_2 \t (3, 1) \t \n",
      " [[ 0.70891729]\n",
      " [-0.07314384]\n",
      " [-0.34590008]] \n",
      "W_3 \t (3, 3) \t \n",
      " [[-4.46121326 -1.30005206  1.48383459]\n",
      " [ 5.47976788 -0.10294374 -2.17885257]\n",
      " [-4.80204286 -0.72026403  4.2899588 ]] \n",
      "b_3 \t (3, 1) \t \n",
      " [[ 0.92696194]\n",
      " [-0.04992975]\n",
      " [ 1.85203693]] \n",
      "W_4 \t (3, 3) \t \n",
      " [[ 4.55322505 -6.43740996  3.23180687]\n",
      " [-1.22845846  1.1087386   2.47830257]\n",
      " [-4.31619948  5.30650489 -6.39851791]] \n",
      "b_4 \t (3, 1) \t \n",
      " [[-0.86812252]\n",
      " [ 0.03418924]\n",
      " [ 0.83393328]] \n"
     ]
    }
   ],
   "source": [
    "for parameter in cls.parameters:\n",
    "    print(\"{} \\t {} \\t \\n {} \".format(parameter, cls.parameters[parameter].shape, cls.parameters[parameter]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.83711323e-01, 1.62881300e-02, 5.46562265e-07],\n",
       "       [9.81387986e-01, 1.86113399e-02, 6.74410701e-07],\n",
       "       [9.82982666e-01, 1.70167483e-02, 5.85569067e-07],\n",
       "       [9.82147239e-01, 1.78521294e-02, 6.31526325e-07],\n",
       "       [9.83893567e-01, 1.61058960e-02, 5.36960030e-07],\n",
       "       [9.83938511e-01, 1.60609543e-02, 5.34664553e-07],\n",
       "       [9.83494201e-01, 1.65052410e-02, 5.58072241e-07],\n",
       "       [9.83418810e-01, 1.65806277e-02, 5.62102016e-07],\n",
       "       [9.80587468e-01, 1.94118116e-02, 7.20738055e-07],\n",
       "       [9.82175136e-01, 1.78242339e-02, 6.29975709e-07],\n",
       "       [9.83915701e-01, 1.60837631e-02, 5.35824908e-07],\n",
       "       [9.83368094e-01, 1.66313416e-02, 5.64809469e-07],\n",
       "       [9.81643763e-01, 1.83555771e-02, 6.59846018e-07],\n",
       "       [9.82472839e-01, 1.75265473e-02, 6.13457206e-07],\n",
       "       [9.84100185e-01, 1.58992890e-02, 5.26247418e-07],\n",
       "       [9.83996289e-01, 1.60031795e-02, 5.31782694e-07],\n",
       "       [9.84079547e-01, 1.59199253e-02, 5.27275207e-07],\n",
       "       [9.83656843e-01, 1.63426076e-02, 5.49446803e-07],\n",
       "       [9.83816836e-01, 1.61826224e-02, 5.41073952e-07],\n",
       "       [9.84029003e-01, 1.59704674e-02, 5.29883587e-07],\n",
       "       [9.83132547e-01, 1.68668759e-02, 5.77489769e-07],\n",
       "       [9.83879918e-01, 1.61195439e-02, 5.37691728e-07],\n",
       "       [9.84090617e-01, 1.59088566e-02, 5.26637045e-07],\n",
       "       [9.82428420e-01, 1.75709637e-02, 6.15934877e-07],\n",
       "       [9.83064756e-01, 1.69346626e-02, 5.81130960e-07],\n",
       "       [9.80704838e-01, 1.92944482e-02, 7.13885525e-07],\n",
       "       [9.83162355e-01, 1.68370688e-02, 5.75867559e-07],\n",
       "       [9.83630088e-01, 1.63693609e-02, 5.50867869e-07],\n",
       "       [9.83462772e-01, 1.65366684e-02, 5.59760636e-07],\n",
       "       [9.82564628e-01, 1.74347638e-02, 6.08405886e-07],\n",
       "       [9.81847821e-01, 1.81515311e-02, 6.48314702e-07],\n",
       "       [9.83169855e-01, 1.68295693e-02, 5.75479270e-07],\n",
       "       [9.84219487e-01, 1.57799931e-02, 5.19994036e-07],\n",
       "       [9.84154756e-01, 1.58447207e-02, 5.23410441e-07],\n",
       "       [9.82018908e-01, 1.79804531e-02, 6.38705663e-07],\n",
       "       [9.83027727e-01, 1.69716895e-02, 5.83131677e-07],\n",
       "       [9.83700346e-01, 1.62991071e-02, 5.47158560e-07],\n",
       "       [9.83945410e-01, 1.60540553e-02, 5.34235612e-07],\n",
       "       [9.81897552e-01, 1.81018025e-02, 6.45508753e-07],\n",
       "       [9.83399315e-01, 1.66001221e-02, 5.63146748e-07],\n",
       "       [9.83734434e-01, 1.62650202e-02, 5.45338406e-07],\n",
       "       [9.21172873e-01, 7.88203831e-02, 6.74422477e-06],\n",
       "       [9.83049557e-01, 1.69498611e-02, 5.81941764e-07],\n",
       "       [9.83295398e-01, 1.67040337e-02, 5.68721411e-07],\n",
       "       [9.83806936e-01, 1.61925221e-02, 5.41547932e-07],\n",
       "       [9.81234179e-01, 1.87651374e-02, 6.83222704e-07],\n",
       "       [9.84028541e-01, 1.59709287e-02, 5.29906766e-07],\n",
       "       [9.82880976e-01, 1.71184328e-02, 5.91092939e-07],\n",
       "       [9.83933988e-01, 1.60654770e-02, 5.34859153e-07],\n",
       "       [9.83193156e-01, 1.68062693e-02, 5.74201286e-07],\n",
       "       [2.22743055e-02, 9.73115235e-01, 4.61045990e-03],\n",
       "       [1.74828734e-02, 9.76916908e-01, 5.60021881e-03],\n",
       "       [2.66452891e-03, 9.54585982e-01, 4.27494887e-02],\n",
       "       [1.82124447e-03, 9.48305248e-01, 4.98735074e-02],\n",
       "       [1.53638957e-03, 9.16987257e-01, 8.14763539e-02],\n",
       "       [2.98119803e-03, 9.68695847e-01, 2.83229552e-02],\n",
       "       [6.34501899e-03, 9.78073541e-01, 1.55814403e-02],\n",
       "       [2.03803970e-02, 9.75381810e-01, 4.23779271e-03],\n",
       "       [5.68866923e-03, 9.79507240e-01, 1.48040905e-02],\n",
       "       [3.86071071e-03, 9.75914732e-01, 2.02245571e-02],\n",
       "       [3.34135453e-03, 9.75128297e-01, 2.15303488e-02],\n",
       "       [8.37226920e-03, 9.81621374e-01, 1.00063564e-02],\n",
       "       [3.92690124e-03, 9.77900470e-01, 1.81726287e-02],\n",
       "       [2.07662088e-03, 9.47257985e-01, 5.06653945e-02],\n",
       "       [1.61546098e-01, 8.37625462e-01, 8.28439567e-04],\n",
       "       [2.76408236e-02, 9.68612647e-01, 3.74652895e-03],\n",
       "       [2.24832986e-03, 9.51903056e-01, 4.58486138e-02],\n",
       "       [2.22400716e-02, 9.73735111e-01, 4.02481690e-03],\n",
       "       [7.24232666e-04, 7.79717383e-01, 2.19558385e-01],\n",
       "       [7.60512509e-03, 9.82708762e-01, 9.68611336e-03],\n",
       "       [3.84770736e-04, 5.07544236e-01, 4.92070994e-01],\n",
       "       [1.64451826e-02, 9.78293688e-01, 5.26112935e-03],\n",
       "       [4.56307031e-04, 6.08057042e-01, 3.91486651e-01],\n",
       "       [3.68663257e-03, 9.74143720e-01, 2.21696469e-02],\n",
       "       [1.33459000e-02, 9.80174965e-01, 6.47913541e-03],\n",
       "       [1.15332918e-02, 9.80774465e-01, 7.69224323e-03],\n",
       "       [1.79218126e-03, 9.32451485e-01, 6.57563333e-02],\n",
       "       [3.10505166e-04, 4.46575683e-01, 5.53113812e-01],\n",
       "       [1.96062717e-03, 9.42766717e-01, 5.52726558e-02],\n",
       "       [5.79563889e-02, 9.40123500e-01, 1.92011083e-03],\n",
       "       [5.93618412e-03, 9.81954027e-01, 1.21097892e-02],\n",
       "       [9.68046902e-03, 9.82578707e-01, 7.74082436e-03],\n",
       "       [1.66586089e-02, 9.78253537e-01, 5.08785430e-03],\n",
       "       [1.07420550e-04, 2.15626380e-01, 7.84266200e-01],\n",
       "       [1.92390271e-03, 9.40986472e-01, 5.70896251e-02],\n",
       "       [3.84233054e-02, 9.58562344e-01, 3.01435035e-03],\n",
       "       [4.36864265e-03, 9.73486882e-01, 2.21444757e-02],\n",
       "       [1.70020294e-03, 9.41800411e-01, 5.64993859e-02],\n",
       "       [4.91350116e-02, 9.48614794e-01, 2.25019392e-03],\n",
       "       [2.82180373e-03, 9.69041683e-01, 2.81365133e-02],\n",
       "       [2.56149475e-03, 9.65141621e-01, 3.22968842e-02],\n",
       "       [4.30917335e-03, 9.75461464e-01, 2.02293629e-02],\n",
       "       [7.18421667e-03, 9.82429216e-01, 1.03865675e-02],\n",
       "       [1.16567992e-02, 9.81745427e-01, 6.59777420e-03],\n",
       "       [3.93676922e-03, 9.76405262e-01, 1.96579691e-02],\n",
       "       [6.82015753e-02, 9.30061883e-01, 1.73654162e-03],\n",
       "       [1.36480715e-02, 9.80173409e-01, 6.17851954e-03],\n",
       "       [1.24380637e-02, 9.80746275e-01, 6.81566134e-03],\n",
       "       [7.61052794e-02, 9.22344298e-01, 1.55042301e-03],\n",
       "       [9.59188687e-03, 9.82158984e-01, 8.24912943e-03],\n",
       "       [4.46947177e-06, 1.58985550e-02, 9.84096975e-01],\n",
       "       [1.42837616e-05, 4.19064095e-02, 9.58079307e-01],\n",
       "       [5.55447274e-06, 1.89860039e-02, 9.81008442e-01],\n",
       "       [1.20826481e-05, 3.60848750e-02, 9.63903042e-01],\n",
       "       [4.83662869e-06, 1.69964754e-02, 9.82998688e-01],\n",
       "       [4.37892600e-06, 1.56670593e-02, 9.84328562e-01],\n",
       "       [5.18949066e-05, 1.22527261e-01, 8.77420844e-01],\n",
       "       [7.67124589e-06, 2.47329098e-02, 9.75259419e-01],\n",
       "       [1.00842784e-05, 3.12993166e-02, 9.68690599e-01],\n",
       "       [6.06099696e-06, 2.02010481e-02, 9.79792891e-01],\n",
       "       [3.08192805e-05, 7.56700219e-02, 9.24299159e-01],\n",
       "       [1.26546378e-05, 3.76745216e-02, 9.62312824e-01],\n",
       "       [7.14208302e-06, 2.32968730e-02, 9.76695985e-01],\n",
       "       [1.05141065e-05, 3.26658451e-02, 9.67323641e-01],\n",
       "       [5.62255306e-06, 1.93373101e-02, 9.80657067e-01],\n",
       "       [7.09559894e-06, 2.30872194e-02, 9.76905685e-01],\n",
       "       [1.84121828e-05, 5.06172600e-02, 9.49364328e-01],\n",
       "       [8.85483568e-06, 2.73417299e-02, 9.72649415e-01],\n",
       "       [3.55399597e-06, 1.32637692e-02, 9.86732677e-01],\n",
       "       [2.19597206e-04, 3.81361960e-01, 6.18418443e-01],\n",
       "       [5.39484900e-06, 1.84917054e-02, 9.81502900e-01],\n",
       "       [1.43732521e-05, 4.20388786e-02, 9.57946748e-01],\n",
       "       [4.59608526e-06, 1.63089212e-02, 9.83686483e-01],\n",
       "       [5.74906773e-05, 1.30167751e-01, 8.69774758e-01],\n",
       "       [8.40101260e-06, 2.64060402e-02, 9.73585559e-01],\n",
       "       [1.58282437e-05, 4.43009709e-02, 9.55683201e-01],\n",
       "       [8.72728104e-05, 1.80511066e-01, 8.19401661e-01],\n",
       "       [9.86287615e-05, 1.95366099e-01, 8.04535272e-01],\n",
       "       [5.67311474e-06, 1.94205551e-02, 9.80573772e-01],\n",
       "       [7.01547936e-05, 1.47713392e-01, 8.52216454e-01],\n",
       "       [7.36599300e-06, 2.39438262e-02, 9.76048808e-01],\n",
       "       [4.70092379e-05, 1.03067833e-01, 8.96885158e-01],\n",
       "       [5.03014695e-06, 1.76007900e-02, 9.82394180e-01],\n",
       "       [3.93912279e-04, 5.41510940e-01, 4.58095148e-01],\n",
       "       [1.08871190e-04, 2.19264509e-01, 7.80626619e-01],\n",
       "       [4.50168153e-06, 1.60119157e-02, 9.83983583e-01],\n",
       "       [6.79765776e-06, 2.22123619e-02, 9.77780840e-01],\n",
       "       [2.12240161e-05, 5.65965355e-02, 9.43382241e-01],\n",
       "       [1.38247620e-04, 2.53699732e-01, 7.46162020e-01],\n",
       "       [9.42122014e-06, 2.90956786e-02, 9.70894900e-01],\n",
       "       [4.72285845e-06, 1.66362453e-02, 9.83359032e-01],\n",
       "       [8.08093764e-06, 2.56561294e-02, 9.74335790e-01],\n",
       "       [1.42837616e-05, 4.19064095e-02, 9.58079307e-01],\n",
       "       [4.80748957e-06, 1.68600859e-02, 9.83135107e-01],\n",
       "       [4.94004077e-06, 1.72071342e-02, 9.82787926e-01],\n",
       "       [6.25443794e-06, 2.09063420e-02, 9.79087404e-01],\n",
       "       [2.06531618e-05, 5.69040552e-02, 9.43075292e-01],\n",
       "       [1.35332092e-05, 3.93090210e-02, 9.60677446e-01],\n",
       "       [1.00332047e-05, 3.03827512e-02, 9.69607216e-01],\n",
       "       [4.02609891e-05, 9.63838692e-02, 9.03575870e-01]])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_prob = cls.predict_proba(X)\n",
    "Y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "Y_hat = cls.predict(X) # отримуємо масив з 0 та 1 \n",
    "Y_hat = np.array(lb.inverse_transform(Y_hat)) # перетворюємо в значення класу, до якого належить приклад\n",
    "print(Y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_accuracy = accuracy_score(Y, Y_hat)\n",
    "custom_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-learn Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(hidden_layer_sizes = (20,), max_iter = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(20,), max_iter=10000)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.98567186e-01, 1.43281337e-03, 1.38052898e-10],\n",
       "       [9.93652714e-01, 6.34728385e-03, 1.92399012e-09],\n",
       "       [9.97554436e-01, 2.44556340e-03, 6.87337695e-10],\n",
       "       [9.94465242e-01, 5.53475378e-03, 3.73589061e-09],\n",
       "       [9.98983516e-01, 1.01648418e-03, 1.07137089e-10],\n",
       "       [9.98255148e-01, 1.74485158e-03, 1.95907667e-10],\n",
       "       [9.97823637e-01, 2.17636181e-03, 1.02737699e-09],\n",
       "       [9.97520126e-01, 2.47987313e-03, 4.44630928e-10],\n",
       "       [9.92628193e-01, 7.37179898e-03, 8.01543345e-09],\n",
       "       [9.95333789e-01, 4.66620994e-03, 1.16411245e-09],\n",
       "       [9.98890762e-01, 1.10923839e-03, 5.28286432e-11],\n",
       "       [9.96954849e-01, 3.04515018e-03, 1.11141572e-09],\n",
       "       [9.95291317e-01, 4.70868215e-03, 1.31239246e-09],\n",
       "       [9.98092600e-01, 1.90739859e-03, 9.14577349e-10],\n",
       "       [9.99762669e-01, 2.37330699e-04, 1.62737555e-12],\n",
       "       [9.99760595e-01, 2.39405240e-04, 4.12493915e-12],\n",
       "       [9.99397087e-01, 6.02912902e-04, 2.47003072e-11],\n",
       "       [9.98127466e-01, 1.87253410e-03, 2.46427891e-10],\n",
       "       [9.97993548e-01, 2.00645206e-03, 9.55931744e-11],\n",
       "       [9.99035497e-01, 9.64503248e-04, 1.08253788e-10],\n",
       "       [9.95168995e-01, 4.83100434e-03, 5.79927401e-10],\n",
       "       [9.98279306e-01, 1.72069354e-03, 3.02842971e-10],\n",
       "       [9.99651462e-01, 3.48538185e-04, 4.47186912e-11],\n",
       "       [9.86725732e-01, 1.32742592e-02, 9.23401259e-09],\n",
       "       [9.93175477e-01, 6.82451756e-03, 5.35439858e-09],\n",
       "       [9.88801059e-01, 1.11989367e-02, 4.50213658e-09],\n",
       "       [9.94462293e-01, 5.53770504e-03, 2.39055519e-09],\n",
       "       [9.98062179e-01, 1.93782069e-03, 1.91869589e-10],\n",
       "       [9.97980683e-01, 2.01931699e-03, 1.77859510e-10],\n",
       "       [9.94515125e-01, 5.48487148e-03, 3.31381769e-09],\n",
       "       [9.92282782e-01, 7.71721411e-03, 4.26225465e-09],\n",
       "       [9.95189752e-01, 4.81024777e-03, 6.46742615e-10],\n",
       "       [9.99767639e-01, 2.32361373e-04, 7.63823084e-12],\n",
       "       [9.99810939e-01, 1.89060650e-04, 2.94927561e-12],\n",
       "       [9.93907814e-01, 6.09218421e-03, 2.07590708e-09],\n",
       "       [9.97917875e-01, 2.08212437e-03, 2.36415517e-10],\n",
       "       [9.98756082e-01, 1.24391820e-03, 3.73286947e-11],\n",
       "       [9.99238118e-01, 7.61881808e-04, 7.61064151e-11],\n",
       "       [9.95866479e-01, 4.13351758e-03, 3.03328118e-09],\n",
       "       [9.97439251e-01, 2.56074888e-03, 3.65580938e-10],\n",
       "       [9.98615483e-01, 1.38451724e-03, 1.77305350e-10],\n",
       "       [9.52731142e-01, 4.72687587e-02, 9.91767865e-08],\n",
       "       [9.97778227e-01, 2.22177198e-03, 1.23799090e-09],\n",
       "       [9.93077065e-01, 6.92293019e-03, 4.85620496e-09],\n",
       "       [9.96292979e-01, 3.70701971e-03, 1.57662988e-09],\n",
       "       [9.91977422e-01, 8.02257411e-03, 4.17144508e-09],\n",
       "       [9.99033410e-01, 9.66590019e-04, 1.02510370e-10],\n",
       "       [9.96899071e-01, 3.10092801e-03, 1.41262498e-09],\n",
       "       [9.98925844e-01, 1.07415611e-03, 6.42488890e-11],\n",
       "       [9.97415893e-01, 2.58410678e-03, 4.12155116e-10],\n",
       "       [1.53093560e-03, 9.92588167e-01, 5.88089742e-03],\n",
       "       [2.44794050e-03, 9.78857184e-01, 1.86948753e-02],\n",
       "       [1.10725107e-03, 9.59939627e-01, 3.89531216e-02],\n",
       "       [2.87612206e-03, 8.97851992e-01, 9.92718863e-02],\n",
       "       [1.35053686e-03, 9.27694061e-01, 7.09554017e-02],\n",
       "       [2.53313047e-03, 8.90576924e-01, 1.06889946e-01],\n",
       "       [2.11650445e-03, 9.31469146e-01, 6.64143493e-02],\n",
       "       [2.13563598e-02, 9.74387484e-01, 4.25615620e-03],\n",
       "       [1.66375253e-03, 9.83612392e-01, 1.47238552e-02],\n",
       "       [5.39314358e-03, 9.23227600e-01, 7.13792567e-02],\n",
       "       [5.97418059e-03, 9.71949160e-01, 2.20766596e-02],\n",
       "       [3.54913650e-03, 9.63761669e-01, 3.26891947e-02],\n",
       "       [2.54682736e-03, 9.88846209e-01, 8.60696399e-03],\n",
       "       [1.70771944e-03, 8.81642803e-01, 1.16649478e-01],\n",
       "       [1.71795502e-02, 9.79538085e-01, 3.28236519e-03],\n",
       "       [2.54334930e-03, 9.92652570e-01, 4.80408106e-03],\n",
       "       [2.61629891e-03, 7.99994554e-01, 1.97389148e-01],\n",
       "       [5.28250301e-03, 9.89931074e-01, 4.78642341e-03],\n",
       "       [6.48519467e-04, 6.06745420e-01, 3.92606060e-01],\n",
       "       [4.70306204e-03, 9.84872477e-01, 1.04244613e-02],\n",
       "       [9.80295837e-04, 4.64687702e-01, 5.34332003e-01],\n",
       "       [4.42166660e-03, 9.89909473e-01, 5.66885992e-03],\n",
       "       [4.38263101e-04, 4.79743983e-01, 5.19817754e-01],\n",
       "       [1.84973325e-03, 9.41081865e-01, 5.70684015e-02],\n",
       "       [2.66303840e-03, 9.90393604e-01, 6.94335751e-03],\n",
       "       [2.11847617e-03, 9.89723368e-01, 8.15815563e-03],\n",
       "       [1.01459819e-03, 9.52029820e-01, 4.69555814e-02],\n",
       "       [6.80284886e-04, 7.12912037e-01, 2.86407678e-01],\n",
       "       [2.08957773e-03, 8.86276271e-01, 1.11634151e-01],\n",
       "       [1.83433210e-02, 9.80814961e-01, 8.41717520e-04],\n",
       "       [4.83747162e-03, 9.83345624e-01, 1.18169045e-02],\n",
       "       [7.11478353e-03, 9.88223707e-01, 4.66150984e-03],\n",
       "       [5.70984527e-03, 9.88165775e-01, 6.12437955e-03],\n",
       "       [1.74907944e-04, 1.70489107e-01, 8.29335985e-01],\n",
       "       [2.61115934e-03, 7.11443580e-01, 2.85945261e-01],\n",
       "       [3.43822625e-03, 9.51388825e-01, 4.51729484e-02],\n",
       "       [1.52620294e-03, 9.70636135e-01, 2.78376616e-02],\n",
       "       [1.26172951e-03, 9.21841274e-01, 7.68969966e-02],\n",
       "       [6.47043519e-03, 9.77227948e-01, 1.63016163e-02],\n",
       "       [3.65135399e-03, 9.39723000e-01, 5.66256460e-02],\n",
       "       [2.68841987e-03, 8.76794024e-01, 1.20517556e-01],\n",
       "       [2.20415437e-03, 9.37479675e-01, 6.03161711e-02],\n",
       "       [3.74439445e-03, 9.84008435e-01, 1.22471705e-02],\n",
       "       [1.56790024e-02, 9.80149563e-01, 4.17143437e-03],\n",
       "       [3.44571067e-03, 9.40763718e-01, 5.57905716e-02],\n",
       "       [6.20339507e-03, 9.82181084e-01, 1.16155212e-02],\n",
       "       [4.07352103e-03, 9.71329293e-01, 2.45971861e-02],\n",
       "       [2.81200605e-03, 9.85995102e-01, 1.11928924e-02],\n",
       "       [4.44060134e-02, 9.54481132e-01, 1.11285480e-03],\n",
       "       [4.08720079e-03, 9.73907532e-01, 2.20052672e-02],\n",
       "       [3.79521550e-07, 1.01271087e-03, 9.98986910e-01],\n",
       "       [2.36175867e-05, 2.42356930e-02, 9.75740689e-01],\n",
       "       [4.38542199e-06, 1.73453739e-02, 9.82650241e-01],\n",
       "       [1.83467358e-05, 3.18544069e-02, 9.68127246e-01],\n",
       "       [1.34987645e-06, 3.62167380e-03, 9.96376976e-01],\n",
       "       [3.07566607e-07, 3.20594917e-03, 9.96793743e-01],\n",
       "       [1.39748691e-04, 5.16815805e-02, 9.48178671e-01],\n",
       "       [3.25950087e-06, 1.98993295e-02, 9.80097411e-01],\n",
       "       [2.90666691e-06, 1.13468286e-02, 9.88650265e-01],\n",
       "       [1.92751225e-06, 6.86577273e-03, 9.93132300e-01],\n",
       "       [2.65872731e-04, 2.66520584e-01, 7.33213543e-01],\n",
       "       [2.52620570e-05, 4.45069097e-02, 9.55467828e-01],\n",
       "       [1.91383385e-05, 4.31534489e-02, 9.56827413e-01],\n",
       "       [8.53086087e-06, 9.59639141e-03, 9.90395078e-01],\n",
       "       [2.19456601e-06, 2.72334860e-03, 9.97274457e-01],\n",
       "       [1.74839380e-05, 2.37430438e-02, 9.76239472e-01],\n",
       "       [6.18412826e-05, 9.92717077e-02, 9.00666451e-01],\n",
       "       [2.94716450e-06, 1.75159773e-02, 9.82481076e-01],\n",
       "       [2.75523146e-08, 7.35224563e-04, 9.99264748e-01],\n",
       "       [7.76410867e-05, 1.05253167e-01, 8.94669192e-01],\n",
       "       [5.71154369e-06, 1.52687758e-02, 9.84725513e-01],\n",
       "       [3.72883585e-05, 2.69435978e-02, 9.73019114e-01],\n",
       "       [2.33768316e-07, 3.30328843e-03, 9.96696478e-01],\n",
       "       [2.34396666e-04, 2.49919384e-01, 7.49846219e-01],\n",
       "       [1.89676463e-05, 3.67081262e-02, 9.63272906e-01],\n",
       "       [3.77144206e-05, 1.21528914e-01, 8.78433372e-01],\n",
       "       [4.21195397e-04, 3.49244476e-01, 6.50334328e-01],\n",
       "       [4.73794061e-04, 3.36952176e-01, 6.62574030e-01],\n",
       "       [2.53393834e-06, 6.06462861e-03, 9.93932837e-01],\n",
       "       [1.17836066e-04, 3.39279223e-01, 6.60602941e-01],\n",
       "       [4.03360863e-06, 2.50054046e-02, 9.74990562e-01],\n",
       "       [5.18041394e-05, 2.30946744e-01, 7.69001452e-01],\n",
       "       [1.45961717e-06, 3.69046640e-03, 9.96308074e-01],\n",
       "       [5.00914983e-04, 4.98565744e-01, 5.00933341e-01],\n",
       "       [4.00535660e-05, 6.62780003e-02, 9.33681946e-01],\n",
       "       [1.45954130e-06, 1.10767173e-02, 9.88921823e-01],\n",
       "       [3.86392134e-06, 5.77911051e-03, 9.94217026e-01],\n",
       "       [7.61130301e-05, 1.04721045e-01, 8.95202842e-01],\n",
       "       [6.18403819e-04, 3.76681242e-01, 6.22700355e-01],\n",
       "       [5.37826082e-05, 1.05838369e-01, 8.94107849e-01],\n",
       "       [2.45073836e-06, 6.16725792e-03, 9.93830291e-01],\n",
       "       [7.48143279e-05, 1.22907409e-01, 8.77017777e-01],\n",
       "       [2.36175867e-05, 2.42356930e-02, 9.75740689e-01],\n",
       "       [1.71063841e-06, 5.24352940e-03, 9.94754760e-01],\n",
       "       [1.79702304e-06, 4.34379800e-03, 9.95654405e-01],\n",
       "       [2.25984820e-05, 4.01546886e-02, 9.59822713e-01],\n",
       "       [4.31798388e-05, 6.50658909e-02, 9.34890929e-01],\n",
       "       [8.61260878e-05, 1.15418050e-01, 8.84495824e-01],\n",
       "       [1.61216757e-05, 1.77253062e-02, 9.82258572e-01],\n",
       "       [1.54958186e-04, 1.19278360e-01, 8.80566682e-01]])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_accuracy = accuracy_score(Y, clf.predict(X))\n",
    "sk_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compare accuracy of custom and sklearn algorithm. \n",
      "\n",
      "   accuracy_custom  accuracy_sk  difference\n",
      "0             0.98         0.98         0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Compare accuracy of custom and sklearn algorithm. \\n\")\n",
    "res_compare_test = pd.DataFrame({'accuracy_custom' : [custom_accuracy], 'accuracy_sk' : [sk_accuracy], 'difference' : [abs(custom_accuracy - sk_accuracy)]})\n",
    "print(res_compare_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
