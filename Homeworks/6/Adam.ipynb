{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import sklearn.linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeuralNet class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet:\n",
    "    \"\"\"\n",
    "    NN for binary classification\n",
    "    Attributes:\n",
    "    ...\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, layers_d, normalize = True, learning_rate = 0.01, num_iter = 30000, stop_eps = 1e-05, epsilon = 1e-08, betha_1 = 0.9, betha_2 = 0.999, k = 500):\n",
    "        self.layers_d = layers_d # тут лише приховані шари а 0-го та останнього (з одним нейроном) немає\n",
    "        self.L = len(self.layers_d) + 1 # кількість шарів нейронів в мережі без урахування вихідного\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_iter = num_iter\n",
    "        self.normalize = normalize\n",
    "        self.stop_eps = stop_eps\n",
    "        self.epsilon = epsilon\n",
    "        self.betha_1 = betha_1\n",
    "        self.betha_2 = betha_2\n",
    "        self.k = k\n",
    "    \n",
    "    def __normalize(self, X, mean = None, std = None):\n",
    "        \"\"\"\n",
    "        Зверніть увагу, що нормалізація вхідних даних є дуже важливою для швидкодії нейронних мереж.\n",
    "        \"\"\"\n",
    "        '''\n",
    "        X.shape =  (n, m)\n",
    "        '''\n",
    "        n = X.shape[0]\n",
    "        m = mean\n",
    "        if m is None:\n",
    "            m = np.mean(X, axis=1).reshape((n, 1))\n",
    "            '''\n",
    "            m.shape =  (n, 1)\n",
    "            '''\n",
    "        s = std\n",
    "        if s is None:\n",
    "            s = np.std(X, axis=1).reshape((n, 1))\n",
    "            '''\n",
    "            s.shape =  (n, 1)\n",
    "            '''\n",
    "        X_new = (X - m) / s\n",
    "        return X_new, m, s\n",
    "\n",
    "    def __sigmoid(self, Z):\n",
    "        \"\"\"\n",
    "        В наступних практичних потрібно буде додати підтримку й інших активаційних функцій - це один з гіперпараметрів. \n",
    "        Їх можна вибирати для всіх шарів одночасно або мати різні активаційні функції на кожному з них.\n",
    "        \"\"\"\n",
    "        return 1 / (1 + np.exp(-Z))\n",
    "    \n",
    "    def __softmax(self, Z):\n",
    "        \n",
    "        x = np.exp(Z)        \n",
    "        '''\n",
    "        Z_i.shape  = (n_l, 1)\n",
    "        x.shape = (n_l, 1)\n",
    "        '''\n",
    "        return x / np.sum(x, axis=0, keepdims = True)\n",
    "    \n",
    "    def __initialize_parameters(self):\n",
    "        \n",
    "        self.parameters = {} \n",
    "        # стоврюємо словник зі значеннями W_i та b_i,ключами в якому будуть назви W_1, w_2, ... та b_1, b_2 і т.д\n",
    "        self.adam = {}\n",
    "        \n",
    "            \n",
    "        for i in range(1, self.L + 1):\n",
    "            \n",
    "            self.adam['VdW_' + str(i)] = 0\n",
    "            self.adam['SdW_' + str(i)] = 0\n",
    "            \n",
    "            \n",
    "            self.adam['Vdb_' + str(i)] = 0            \n",
    "            self.adam['Sdb_' + str(i)] = 0\n",
    "            self.parameters['W_' + str(i)] = np.random.randn(self.layers_d[i], self.layers_d[i - 1])* np.sqrt(2/self.layers_d[i - 1])\n",
    "            '''\n",
    "            W_i.shape  = (n_l, n_l-1) # (кількість нейронів на поточному шарі, кількість на попередньому)\n",
    "            '''\n",
    "            self.parameters['b_' + str(i)] = np.zeros((self.layers_d[i],1))\n",
    "            '''\n",
    "            b_i.shape  = (n_l,1) # (кількість нейронів на поточному шарі, 1)\n",
    "            '''\n",
    "       \n",
    "    def __forward_propagation(self, X):\n",
    "        \n",
    "        cache = {} # стоврюємо словник зі значеннями Z_i та A_i,ключами в якому будуть назви A_0, A_1, A_2, ... та Z_1, Z_2 і т.д\n",
    "        cache['A_0'] = X\n",
    "        \n",
    "        for i in range(1, self.L):\n",
    "            cache['Z_' + str(i)] = np.dot(self.parameters['W_' + str(i)], cache['A_' + str(i - 1)]) + self.parameters['b_' + str(i)]\n",
    "            '''\n",
    "            Z_i.shape  = (n_l, 1) = (n_l, n_l-1) * (n_l-1, 1) + (n_l,1)\n",
    "            '''\n",
    "            cache['A_' + str(i)] = self.__sigmoid(cache['Z_' + str(i)])\n",
    "            '''\n",
    "            A_i.shape  = (n_l, 1) = (n_l, 1)\n",
    "            '''       \n",
    "        cache['Z_' + str(self.L)] = np.dot(self.parameters['W_' + str(self.L)], cache['A_' + str(self.L - 1)]) + self.parameters['b_' + str(self.L)]\n",
    "        cache['A_' + str(self.L)] = self.__softmax(cache['Z_' + str(self.L)])\n",
    "        '''\n",
    "        функція softmax на останньому кроці \n",
    "        ''' \n",
    "        return cache['A_' + str(self.L)], cache\n",
    "    \n",
    "    def compute_cost(self, A, Y):\n",
    "        m = Y.shape[1]\n",
    "        res = Y * np.log(A) + (1 - Y) * np.log(1 - A)\n",
    "        J = -(1 / m) * np.sum(res)\n",
    "        '''\n",
    "        J.shape  = sum((1, m) x (1, m) - (1, m) x (1, m)) = sum((1, m)) = (1, 1)\n",
    "        '''\n",
    "        return J\n",
    "        \n",
    "    def __backward_propagation(self, X, Y, cache):\n",
    "        \n",
    "        m = X.shape[1]\n",
    "        gradients = {}\n",
    "        \n",
    "        gradients['dZ_' + str(self.L)] = cache['A_' + str(self.L)] - Y\n",
    "        '''\n",
    "        dZ_L.shape  = (1, m) - (1, m) = (1, m)\n",
    "        '''\n",
    "        gradients['dW_' + str(self.L)] = (1/m) * np.dot (gradients['dZ_' + str(self.L)], cache['A_' + str(self.L - 1)].T)\n",
    "        '''\n",
    "        dW_L.shape  = (1, m) * ((n_l-1, m).T) = (1, m) * (m, n_l-1) = (1, n_l-1)\n",
    "        '''\n",
    "        gradients['db_' + str(self.L)] = (1/m) * np.sum(gradients['dZ_' + str(self.L)], axis = 1, keepdims = True)\n",
    "        '''\n",
    "        db_L.shape  = sum((1, m)) = (1, 1)\n",
    "        '''\n",
    "        \n",
    "        for i in range(self.L - 1, 0, -1):\n",
    "            dA_i = np.dot (self.parameters['W_' + str(i + 1)].T, gradients['dZ_' + str(i + 1)])\n",
    "            '''\n",
    "            dA_i.shape  = (n_l-1, n_l)*(n_l, m) = (n_l-1, m)\n",
    "            '''\n",
    "            gradients['dZ_' + str(i)] = np.multiply(dA_i, cache['A_' + str(i)] * (1 - cache['A_' + str(i)]))\n",
    "            '''\n",
    "            dZ_i.shape  = (n_l, m)x(n_l, m) = (n_l, m)\n",
    "            '''\n",
    "            gradients['dW_' + str(i)] = (1/m) * np.dot (gradients['dZ_' + str(i)], cache['A_' + str(i - 1)].T)\n",
    "            '''\n",
    "            dW_i.shape  = (n_l, m)*((n_l-1, n).T) = (n_l, m)*(m, n_l-1) = (n_l, n_l-1)\n",
    "            '''\n",
    "            gradients['db_' + str(i)] = (1/m) * np.sum(gradients['dZ_' + str(i)], axis = 1, keepdims = True)\n",
    "            '''\n",
    "            db_i.shape = sum((n_l, m)) = (n_l, 1)\n",
    "            '''       \n",
    "        \n",
    "        return gradients\n",
    "    \n",
    "    def __update_parameters(self, gradients, t):\n",
    "          \n",
    "        for i in range(1, self.L + 1):            \n",
    "            \n",
    "            self.adam['VdW_' + str(i)] = self.betha_1 * self.adam['VdW_' + str(i)] + (1 - self.betha_1) * gradients['dW_' + str(i)]  \n",
    "            self.adam['SdW_' + str(i)] = self.betha_2 * self.adam['SdW_' + str(i)] + (1 - self.betha_2) * (gradients['dW_' + str(i)]**2)\n",
    "            \n",
    "            self.adam['VdW_corr_' + str(i)] = self.adam['VdW_' + str(i)] / (1 - self.betha_1**(t + 1))\n",
    "            self.adam['SdW_corr_' + str(i)] = self.adam['SdW_' + str(i)] / (1 - self.betha_2**(t + 1))\n",
    "            \n",
    "            self.parameters['W_' + str(i)] = self.parameters['W_' + str(i)] - (self.learning_rate * self.adam['VdW_corr_' + str(i)] ) /(self.adam['SdW_corr_' + str(i)]**(0.5) + self.epsilon)\n",
    "            '''\n",
    "            #W_i.shape  = (n_l, n_l-1) # (кількість нейронів на поточному шарі, кількість на попередньому)\n",
    "            '''\n",
    "\n",
    "            self.adam['Vdb_' + str(i)] =  self.betha_1 * self.adam['Vdb_' + str(i)] + (1 - self.betha_1) * gradients['db_' + str(i)]  \n",
    "            self.adam['Sdb_' + str(i)] =  self.betha_2 * self.adam['Sdb_' + str(i)] + (1 - self.betha_2) * (gradients['db_' + str(i)]**2)          \n",
    "            \n",
    "            self.adam['Vdb_corr_' + str(i)] = self.adam['Vdb_' + str(i)] / (1 - self.betha_1**(t + 1))        \n",
    "            self.adam['Sdb_corr_' + str(i)] = self.adam['Sdb_' + str(i)] / (1 - self.betha_2**(t + 1))\n",
    "\n",
    "            self.parameters['b_' + str(i)] = self.parameters['b_' + str(i)] - (self.learning_rate * self.adam['Vdb_corr_' + str(i)]) / (self.adam['Sdb_corr_' + str(i)]**(0.5) + self.epsilon)\n",
    "            \n",
    "            '''\n",
    "            #b_i.shape  = (n_l,1) # (кількість нейронів на поточному шарі, 1)\n",
    "            '''\n",
    "            \n",
    "           \n",
    "            '''\n",
    "            self.parameters['W_' + str(i)] -= self.learning_rate * gradients['dW_' + str(i)]\n",
    "            self.parameters['b_' + str(i)] -= self.learning_rate * gradients['db_' + str(i)]\n",
    "         '''\n",
    "           \n",
    "        \n",
    "    \n",
    "    def fit(self, X_vert, Y_vert, print_cost = True):\n",
    "        X= X_vert.T\n",
    "        \n",
    "        n_x = X.shape[0] # визначаємо кількість нейронів у вихідному шарі\n",
    "                \n",
    "        lb = LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False) \n",
    "        # задаємо перетворення приналежності до класів як 0 і 1 відвідно для кожного прикладу \n",
    "        #([0, 0, 1] - приклад з класу 2, [1, 0, 0] - приклад з класу 0, [0, 1, 0] - приклад з класу 1)\n",
    "        lb.fit(Y_vert)\n",
    "        \n",
    "        Y = lb.transform(Y_vert).T        \n",
    "        final_classes = Y.shape[0] # визначаємо кількість нейронів у вихідному шарі\n",
    "        \n",
    "        self.layers_d.insert(0, n_x)\n",
    "        self.layers_d.append(final_classes) \n",
    "        '''\n",
    "        додаємо вхідний та вихідний шари до прихованих \n",
    "        і отримуємо клькість всіх шарів нейронної мережі і кількість нейронів на кожному шарі\n",
    "        '''\n",
    "        \n",
    "        if self.normalize:\n",
    "            X, self.__mean, self.__std = self.__normalize(X)\n",
    "        \n",
    "        costs = []\n",
    "        \n",
    "        m = X.shape[1]\n",
    "        n_x = X.shape[0]\n",
    "        \n",
    "        self.__initialize_parameters()\n",
    "        \n",
    "        previous_cost = 0;\n",
    "\n",
    "        for i in range(self.num_iter):\n",
    "            \n",
    "            A, cache = self.__forward_propagation(X)\n",
    "\n",
    "            cost = self.compute_cost(A, Y)\n",
    "\n",
    "            gradients = self.__backward_propagation(X, Y, cache)\n",
    "\n",
    "            self.__update_parameters(gradients, i)\n",
    "\n",
    "            if print_cost and i % 100 == 0:\n",
    "                print(\"{}-th iteration: {}\".format(i, cost))\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                costs.append(cost)\n",
    "            if (abs(previous_cost - cost) < self.stop_eps):\n",
    "                self.k = self.k - 1\n",
    "                if (self.k == 0):\n",
    "                    break;\n",
    "                    \n",
    "            previous_cost = cost\n",
    "\n",
    "        if print_cost:\n",
    "            plt.plot(costs)\n",
    "            plt.ylabel(\"Cost\")\n",
    "            plt.xlabel(\"Iteration, *100\")\n",
    "            plt.show()  \n",
    "            \n",
    "           \n",
    "    def predict_proba(self, X_vert):\n",
    "        X = X_vert.T\n",
    "        if self.normalize:\n",
    "            X, _, _ = self.__normalize(X, self.__mean, self.__std)    \n",
    "        \n",
    "        probs = self.__forward_propagation(X)[0]\n",
    "        return probs.T\n",
    "    \n",
    "    def predict(self, X_vert):\n",
    "        probs = self.predict_proba(X_vert)\n",
    "        results_bin = (probs == probs.max(axis=1)[:, None]).astype(int)\n",
    "        '''\n",
    "        максимальне значення в кожному рядку перетворюємо на 1 а інші задаємо як 0\n",
    "        наприклад, \n",
    "        a = np.array([[0, 1], [2, 2], [4, 3]])\n",
    "        (a == a.max(axis=1)[:,None]).astype(int)\n",
    "        \n",
    "        Результат : \n",
    "        array([[0, 1], [1, 1], [1, 0]])\n",
    "        '''\n",
    "        return results_bin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "X, Y = load_iris(return_X_y = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "lb = LabelBinarizer(sparse_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = lb.fit(Y) # перетворюємо значення Y масив значеннь з 0 та 1, де 1 - приналежність до відповідного по порядку класу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb.transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = NeuralNet([4, 3, 3],normalize = True, learning_rate = 0.05, betha_1 = 0.9, betha_2 = 0.999, num_iter = 10000, stop_eps = 1e-06, epsilon = 1e-08, k = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-th iteration: 1.995004838221502\n",
      "100-th iteration: 0.19875718465704184\n",
      "200-th iteration: 0.08103225797246622\n",
      "300-th iteration: 0.0714086547918564\n",
      "400-th iteration: 0.0689058219121147\n",
      "500-th iteration: 0.06778966195429237\n",
      "600-th iteration: 0.06713457246884867\n",
      "700-th iteration: 0.06651491235186999\n",
      "800-th iteration: 0.06219930424421915\n",
      "900-th iteration: 0.04873081652924523\n",
      "1000-th iteration: 0.04047465855314599\n",
      "1100-th iteration: 0.03691879525600805\n",
      "1200-th iteration: 0.035729902009924173\n",
      "1300-th iteration: 0.03510743347346718\n",
      "1400-th iteration: 0.034722814957680884\n",
      "1500-th iteration: 0.034462817786295834\n",
      "1600-th iteration: 0.03427613942823977\n",
      "1700-th iteration: 0.03413612322904365\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cls.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_1 \t \n",
      " [[ -3.68438033   7.82492068  -1.97482228  -2.18992731]\n",
      " [ -0.98620296  -0.97297252  -1.29562453  -8.73870651]\n",
      " [  3.88175514  -0.08202598 -12.83849973  -0.74685022]\n",
      " [  0.67101523  -0.87663284   1.39264997   3.06463391]] \n",
      "b_1 \t \n",
      " [[3.12174392]\n",
      " [6.53919939]\n",
      " [6.72973255]\n",
      " [1.47167305]] \n",
      "W_2 \t \n",
      " [[ -1.77112567 -11.92104561   1.4517116    3.04295842]\n",
      " [  9.39226997   1.86792359  17.69995991  -6.5545089 ]\n",
      " [ -3.10908921   0.73272752  -2.09698115   5.19534964]] \n",
      "b_2 \t \n",
      " [[-0.79377911]\n",
      " [-6.06346738]\n",
      " [ 1.68019224]] \n",
      "W_3 \t \n",
      " [[ 1.92246024 -2.60874742  4.52380499]\n",
      " [-2.62473237  2.43032591 -7.76613634]\n",
      " [-5.45114016  6.44074193 -2.53773947]] \n",
      "b_3 \t \n",
      " [[-1.55084203]\n",
      " [ 1.21313902]\n",
      " [ 2.35746   ]] \n",
      "W_4 \t \n",
      " [[-5.8534207   7.72819488  2.52820684]\n",
      " [-0.16042477 -8.05172046  5.99350979]\n",
      " [ 6.0778457  -1.96894575 -9.52945436]] \n",
      "b_4 \t \n",
      " [[-2.67600807]\n",
      " [-0.2473179 ]\n",
      " [ 2.2724272 ]] \n"
     ]
    }
   ],
   "source": [
    "for parameter in cls.parameters:\n",
    "    print(\"{} \\t \\n {} \".format(parameter, cls.parameters[parameter])) #cls.parameters[parameter].shape \\t {} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99893564e-01, 1.06342040e-04, 9.37280358e-08],\n",
       "       [9.99893002e-01, 1.06904195e-04, 9.41043691e-08],\n",
       "       [9.99893471e-01, 1.06435119e-04, 9.37903930e-08],\n",
       "       [9.99893306e-01, 1.06600301e-04, 9.39010101e-08],\n",
       "       [9.99893667e-01, 1.06239359e-04, 9.36592243e-08],\n",
       "       [9.99893305e-01, 1.06601066e-04, 9.39015226e-08],\n",
       "       [9.99893472e-01, 1.06433914e-04, 9.37895862e-08],\n",
       "       [9.99893472e-01, 1.06434412e-04, 9.37899193e-08],\n",
       "       [9.99893185e-01, 1.06720605e-04, 9.39815384e-08],\n",
       "       [9.99893406e-01, 1.06500172e-04, 9.38339639e-08],\n",
       "       [9.99893597e-01, 1.06309776e-04, 9.37064162e-08],\n",
       "       [9.99893513e-01, 1.06393505e-04, 9.37625164e-08],\n",
       "       [9.99893381e-01, 1.06524827e-04, 9.38504751e-08],\n",
       "       [9.99893667e-01, 1.06239629e-04, 9.36594053e-08],\n",
       "       [9.99893752e-01, 1.06154865e-04, 9.36025842e-08],\n",
       "       [9.99893713e-01, 1.06193279e-04, 9.36283367e-08],\n",
       "       [9.99893490e-01, 1.06416696e-04, 9.37780524e-08],\n",
       "       [9.99893356e-01, 1.06550220e-04, 9.38674786e-08],\n",
       "       [9.99893276e-01, 1.06630548e-04, 9.39212596e-08],\n",
       "       [9.99893612e-01, 1.06293851e-04, 9.36957445e-08],\n",
       "       [9.99893152e-01, 1.06754279e-04, 9.40040733e-08],\n",
       "       [9.99893304e-01, 1.06602003e-04, 9.39021496e-08],\n",
       "       [9.99893815e-01, 1.06091447e-04, 9.35600626e-08],\n",
       "       [9.99891223e-01, 1.08681303e-04, 9.52897338e-08],\n",
       "       [9.99893386e-01, 1.06519686e-04, 9.38470322e-08],\n",
       "       [9.99892730e-01, 1.07175321e-04, 9.42856378e-08],\n",
       "       [9.99892732e-01, 1.07173437e-04, 9.42843782e-08],\n",
       "       [9.99893491e-01, 1.06414770e-04, 9.37767619e-08],\n",
       "       [9.99893427e-01, 1.06478953e-04, 9.38197527e-08],\n",
       "       [9.99893333e-01, 1.06572717e-04, 9.38825424e-08],\n",
       "       [9.99893119e-01, 1.06787251e-04, 9.40261356e-08],\n",
       "       [9.99892374e-01, 1.07531564e-04, 9.45235806e-08],\n",
       "       [9.99893882e-01, 1.06024232e-04, 9.35149853e-08],\n",
       "       [9.99893840e-01, 1.06066890e-04, 9.35435946e-08],\n",
       "       [9.99893117e-01, 1.06789167e-04, 9.40274182e-08],\n",
       "       [9.99893379e-01, 1.06527004e-04, 9.38519326e-08],\n",
       "       [9.99893447e-01, 1.06458717e-04, 9.38061994e-08],\n",
       "       [9.99893787e-01, 1.06119347e-04, 9.35787702e-08],\n",
       "       [9.99893382e-01, 1.06523976e-04, 9.38499050e-08],\n",
       "       [9.99893428e-01, 1.06477756e-04, 9.38189512e-08],\n",
       "       [9.99893449e-01, 1.06457044e-04, 9.38050792e-08],\n",
       "       [9.99791485e-01, 2.08359987e-04, 1.54519064e-07],\n",
       "       [9.99893582e-01, 1.06324526e-04, 9.37163001e-08],\n",
       "       [9.99891650e-01, 1.08254660e-04, 9.50057475e-08],\n",
       "       [9.99893221e-01, 1.06685201e-04, 9.39578431e-08],\n",
       "       [9.99892621e-01, 1.07284446e-04, 9.43585524e-08],\n",
       "       [9.99893714e-01, 1.06192040e-04, 9.36275060e-08],\n",
       "       [9.99893472e-01, 1.06434017e-04, 9.37896550e-08],\n",
       "       [9.99893627e-01, 1.06279767e-04, 9.36863060e-08],\n",
       "       [9.99893405e-01, 1.06501215e-04, 9.38346626e-08],\n",
       "       [1.35027398e-04, 9.99769745e-01, 9.52279844e-05],\n",
       "       [2.11643538e-04, 9.99718351e-01, 7.00053981e-05],\n",
       "       [1.25663699e-04, 9.99773485e-01, 1.00851760e-04],\n",
       "       [1.27831310e-04, 9.99772907e-01, 9.92618262e-05],\n",
       "       [1.27173035e-04, 9.99773127e-01, 9.97002547e-05],\n",
       "       [8.30208405e-05, 9.99765793e-01, 1.51185681e-04],\n",
       "       [2.50059269e-04, 9.99686472e-01, 6.34689156e-05],\n",
       "       [1.46705425e-04, 9.99763670e-01, 8.96241344e-05],\n",
       "       [1.28303960e-04, 9.99772737e-01, 9.89594710e-05],\n",
       "       [1.34722459e-04, 9.99769904e-01, 9.53738709e-05],\n",
       "       [1.31784178e-04, 9.99771254e-01, 9.69622127e-05],\n",
       "       [1.62319465e-04, 9.99754242e-01, 8.34388557e-05],\n",
       "       [1.29274885e-04, 9.99772347e-01, 9.83784663e-05],\n",
       "       [9.77504528e-05, 9.99774107e-01, 1.28142474e-04],\n",
       "       [2.63006504e-04, 9.99675582e-01, 6.14116785e-05],\n",
       "       [1.34371708e-04, 9.99770073e-01, 9.55551457e-05],\n",
       "       [1.44784491e-04, 9.99764418e-01, 9.07972495e-05],\n",
       "       [1.35216371e-04, 9.99769666e-01, 9.51179570e-05],\n",
       "       [1.26390702e-04, 9.99773409e-01, 1.00199874e-04],\n",
       "       [1.30933611e-04, 9.99771630e-01, 9.74360810e-05],\n",
       "       [3.09421527e-05, 9.98793131e-01, 1.17592723e-03],\n",
       "       [1.29986298e-04, 9.99772052e-01, 9.79620933e-05],\n",
       "       [2.71650777e-05, 9.98050531e-01, 1.92230428e-03],\n",
       "       [1.06922375e-04, 9.99775673e-01, 1.17404259e-04],\n",
       "       [1.29596158e-04, 9.99772217e-01, 9.81866553e-05],\n",
       "       [1.29761324e-04, 9.99772144e-01, 9.80949166e-05],\n",
       "       [1.27242365e-04, 9.99773121e-01, 9.96366761e-05],\n",
       "       [2.98370595e-05, 9.97788237e-01, 2.18192630e-03],\n",
       "       [1.26694967e-04, 9.99773152e-01, 1.00153307e-04],\n",
       "       [1.38486877e-04, 9.99768057e-01, 9.34564178e-05],\n",
       "       [1.30755187e-04, 9.99771709e-01, 9.75356648e-05],\n",
       "       [1.33376571e-04, 9.99770530e-01, 9.60934352e-05],\n",
       "       [1.31284790e-04, 9.99771483e-01, 9.72318162e-05],\n",
       "       [1.63727546e-05, 1.97454470e-01, 8.02529158e-01],\n",
       "       [1.09756624e-04, 9.99772965e-01, 1.17278694e-04],\n",
       "       [2.92921387e-04, 9.99649184e-01, 5.78944075e-05],\n",
       "       [1.30300697e-04, 9.99771823e-01, 9.78761952e-05],\n",
       "       [1.27612850e-04, 9.99773014e-01, 9.93733123e-05],\n",
       "       [3.26095152e-04, 9.99619313e-01, 5.45913668e-05],\n",
       "       [1.28362779e-04, 9.99772695e-01, 9.89426335e-05],\n",
       "       [4.52912718e-05, 9.99644667e-01, 3.10041562e-04],\n",
       "       [1.34982979e-04, 9.99769758e-01, 9.52594813e-05],\n",
       "       [1.29641676e-04, 9.99772189e-01, 9.81690852e-05],\n",
       "       [1.39087605e-04, 9.99767750e-01, 9.31622724e-05],\n",
       "       [1.28310335e-04, 9.99772657e-01, 9.90322083e-05],\n",
       "       [3.44498289e-04, 9.99602428e-01, 5.30741293e-05],\n",
       "       [1.56860648e-04, 9.99757685e-01, 8.54545915e-05],\n",
       "       [1.31047792e-04, 9.99771593e-01, 9.73588907e-05],\n",
       "       [1.47155541e-04, 9.99763419e-01, 8.94251165e-05],\n",
       "       [1.33880240e-04, 9.99770306e-01, 9.58136466e-05],\n",
       "       [5.82687035e-08, 1.90153562e-04, 9.99809788e-01],\n",
       "       [8.43411351e-08, 2.88441799e-04, 9.99711474e-01],\n",
       "       [5.58775635e-08, 1.82151435e-04, 9.99817793e-01],\n",
       "       [7.11264562e-08, 2.36985282e-04, 9.99762944e-01],\n",
       "       [5.59526381e-08, 1.82401530e-04, 9.99817543e-01],\n",
       "       [5.59267752e-08, 1.82316168e-04, 9.99817628e-01],\n",
       "       [1.64454084e-05, 1.98630413e-01, 8.01353142e-01],\n",
       "       [5.69860241e-08, 1.85861272e-04, 9.99814082e-01],\n",
       "       [8.53211835e-08, 2.92363831e-04, 9.99707551e-01],\n",
       "       [6.33394378e-08, 2.07737537e-04, 9.99792199e-01],\n",
       "       [5.68398733e-08, 1.85196826e-04, 9.99814746e-01],\n",
       "       [5.98368454e-08, 1.95664456e-04, 9.99804276e-01],\n",
       "       [5.56656351e-08, 1.81444778e-04, 9.99818500e-01],\n",
       "       [6.44226446e-08, 2.12063319e-04, 9.99787872e-01],\n",
       "       [5.58980145e-08, 1.82219669e-04, 9.99817724e-01],\n",
       "       [5.66511009e-08, 1.84700655e-04, 9.99815243e-01],\n",
       "       [6.26052403e-08, 2.05487326e-04, 9.99794450e-01],\n",
       "       [7.59144217e-08, 2.53541009e-04, 9.99746383e-01],\n",
       "       [5.59195623e-08, 1.82292358e-04, 9.99817652e-01],\n",
       "       [1.65377053e-05, 2.00054888e-01, 7.99928575e-01],\n",
       "       [5.58786710e-08, 1.82152962e-04, 9.99817791e-01],\n",
       "       [5.98640631e-08, 1.95761235e-04, 9.99804179e-01],\n",
       "       [5.59674871e-08, 1.82451268e-04, 9.99817493e-01],\n",
       "       [2.15836267e-07, 8.87763714e-04, 9.99112020e-01],\n",
       "       [5.76617543e-08, 1.88096983e-04, 9.99811845e-01],\n",
       "       [5.66328350e-08, 1.84669232e-04, 9.99815274e-01],\n",
       "       [3.05802534e-07, 1.35171157e-03, 9.98647983e-01],\n",
       "       [1.06499184e-07, 3.79468206e-04, 9.99620425e-01],\n",
       "       [5.60761564e-08, 1.82811735e-04, 9.99817132e-01],\n",
       "       [2.60006692e-07, 1.11853752e-03, 9.98881202e-01],\n",
       "       [5.62035786e-08, 1.83234602e-04, 9.99816709e-01],\n",
       "       [7.63871362e-08, 2.55189755e-04, 9.99744734e-01],\n",
       "       [5.59515409e-08, 1.82397864e-04, 9.99817546e-01],\n",
       "       [1.67815708e-05, 2.03837858e-01, 7.96145361e-01],\n",
       "       [1.64448119e-05, 1.98645347e-01, 8.01338208e-01],\n",
       "       [5.56752260e-08, 1.81478800e-04, 9.99818466e-01],\n",
       "       [7.32737307e-08, 2.43713720e-04, 9.99756213e-01],\n",
       "       [6.34791892e-08, 2.08616718e-04, 9.99791320e-01],\n",
       "       [1.83189888e-07, 7.28255496e-04, 9.99271561e-01],\n",
       "       [5.52000569e-08, 1.79898936e-04, 9.99820046e-01],\n",
       "       [5.58609992e-08, 1.82096073e-04, 9.99817848e-01],\n",
       "       [1.36058381e-07, 4.96121034e-04, 9.99503743e-01],\n",
       "       [8.43411351e-08, 2.88441799e-04, 9.99711474e-01],\n",
       "       [5.59897250e-08, 1.82522851e-04, 9.99817421e-01],\n",
       "       [5.64285891e-08, 1.83972860e-04, 9.99815971e-01],\n",
       "       [5.49994820e-08, 1.79236097e-04, 9.99820709e-01],\n",
       "       [6.69897149e-08, 2.21419884e-04, 9.99778513e-01],\n",
       "       [5.56599462e-08, 1.81414366e-04, 9.99818530e-01],\n",
       "       [8.19435560e-08, 2.76245367e-04, 9.99723673e-01],\n",
       "       [2.45725349e-07, 1.04325981e-03, 9.98956494e-01]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_prob = cls.predict_proba(X)\n",
    "Y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "Y_hat = cls.predict(X) # отримуємо масив з 0 та 1 \n",
    "Y_hat = np.array(lb.inverse_transform(Y_hat)) # перетворюємо в значення класу, до якого належить приклад\n",
    "print(Y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9933333333333333"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_accuracy = accuracy_score(Y, Y_hat)\n",
    "custom_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-learn Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(hidden_layer_sizes = (20,), max_iter = 10000,  solver = 'adam') #, activation = 'logistic', solver = 'sgd', learning_rate_init = 0.01, learning_rate = 'constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(20,), max_iter=10000)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.96882629e-01, 3.11737090e-03, 3.53588255e-12],\n",
       "       [9.91281546e-01, 8.71845356e-03, 6.31356820e-11],\n",
       "       [9.94811401e-01, 5.18859894e-03, 2.44373220e-11],\n",
       "       [9.89243317e-01, 1.07566832e-02, 1.76632455e-10],\n",
       "       [9.97257574e-01, 2.74242576e-03, 2.97581051e-12],\n",
       "       [9.95017253e-01, 4.98274683e-03, 5.04498864e-12],\n",
       "       [9.93381841e-01, 6.61815896e-03, 4.43201619e-11],\n",
       "       [9.94945508e-01, 5.05449167e-03, 1.38665889e-11],\n",
       "       [9.86603574e-01, 1.33964253e-02, 4.29664242e-10],\n",
       "       [9.93229167e-01, 6.77083293e-03, 4.00336728e-11],\n",
       "       [9.97632164e-01, 2.36783573e-03, 1.08528488e-12],\n",
       "       [9.92794660e-01, 7.20533952e-03, 4.57393985e-11],\n",
       "       [9.93320386e-01, 6.67961444e-03, 4.59733237e-11],\n",
       "       [9.95855684e-01, 4.14431590e-03, 3.10755507e-11],\n",
       "       [9.99475604e-01, 5.24396483e-04, 1.34070903e-14],\n",
       "       [9.98959843e-01, 1.04015651e-03, 6.11690207e-14],\n",
       "       [9.98157072e-01, 1.84292832e-03, 4.32191828e-13],\n",
       "       [9.95771273e-01, 4.22872716e-03, 6.54969037e-12],\n",
       "       [9.96247402e-01, 3.75259796e-03, 1.81185147e-12],\n",
       "       [9.96854525e-01, 3.14547534e-03, 3.02328638e-12],\n",
       "       [9.93294192e-01, 6.70580755e-03, 1.48347018e-11],\n",
       "       [9.94885040e-01, 5.11496033e-03, 8.89088503e-12],\n",
       "       [9.98727479e-01, 1.27252132e-03, 8.05136436e-13],\n",
       "       [9.76727150e-01, 2.32728495e-02, 3.53099870e-10],\n",
       "       [9.84892920e-01, 1.51070798e-02, 2.87232759e-10],\n",
       "       [9.86468299e-01, 1.35317011e-02, 1.60897111e-10],\n",
       "       [9.88119599e-01, 1.18804014e-02, 8.76057447e-11],\n",
       "       [9.96210904e-01, 3.78909568e-03, 4.88969453e-12],\n",
       "       [9.96456603e-01, 3.54339650e-03, 4.20114881e-12],\n",
       "       [9.89097032e-01, 1.09029680e-02, 1.53803315e-10],\n",
       "       [9.87620225e-01, 1.23797743e-02, 1.82546136e-10],\n",
       "       [9.92398585e-01, 7.60141540e-03, 1.47972419e-11],\n",
       "       [9.99061972e-01, 9.38027594e-04, 1.64290399e-13],\n",
       "       [9.99295462e-01, 7.04537834e-04, 4.33992088e-14],\n",
       "       [9.90827320e-01, 9.17267973e-03, 7.40595924e-11],\n",
       "       [9.96520972e-01, 3.47902839e-03, 5.51494213e-12],\n",
       "       [9.97986349e-01, 2.01365068e-03, 5.91541009e-13],\n",
       "       [9.97867999e-01, 2.13200068e-03, 2.14647086e-12],\n",
       "       [9.91258384e-01, 8.74161566e-03, 1.46864964e-10],\n",
       "       [9.95208188e-01, 4.79181230e-03, 1.03758322e-11],\n",
       "       [9.96520663e-01, 3.47933743e-03, 4.73664515e-12],\n",
       "       [9.56450063e-01, 4.35499326e-02, 4.74876447e-09],\n",
       "       [9.93911169e-01, 6.08883093e-03, 5.83236191e-11],\n",
       "       [9.81854426e-01, 1.81455737e-02, 1.88394276e-10],\n",
       "       [9.88511312e-01, 1.14886877e-02, 6.51011167e-11],\n",
       "       [9.87750439e-01, 1.22495610e-02, 1.57209408e-10],\n",
       "       [9.97027047e-01, 2.97295257e-03, 3.01637303e-12],\n",
       "       [9.92987424e-01, 7.01257618e-03, 6.03192498e-11],\n",
       "       [9.97502030e-01, 2.49797016e-03, 1.45060258e-12],\n",
       "       [9.95272871e-01, 4.72712882e-03, 1.19149370e-11],\n",
       "       [7.17328610e-03, 9.91236700e-01, 1.59001386e-03],\n",
       "       [8.17185433e-03, 9.85096496e-01, 6.73164940e-03],\n",
       "       [4.55604724e-03, 9.77765660e-01, 1.76782926e-02],\n",
       "       [7.66863651e-03, 9.32443122e-01, 5.98882411e-02],\n",
       "       [4.71408663e-03, 9.60919357e-01, 3.43665567e-02],\n",
       "       [6.83219447e-03, 9.08195876e-01, 8.49719297e-02],\n",
       "       [5.99323087e-03, 9.60132221e-01, 3.38745484e-02],\n",
       "       [3.89637132e-02, 9.59693874e-01, 1.34241273e-03],\n",
       "       [6.99217734e-03, 9.87312547e-01, 5.69527573e-03],\n",
       "       [1.12302584e-02, 9.50913936e-01, 3.78558055e-02],\n",
       "       [1.59424855e-02, 9.74024368e-01, 1.00331461e-02],\n",
       "       [9.47468332e-03, 9.77647999e-01, 1.28773180e-02],\n",
       "       [1.01641130e-02, 9.86968732e-01, 2.86715496e-03],\n",
       "       [5.23137789e-03, 9.06127573e-01, 8.86410495e-02],\n",
       "       [2.97950704e-02, 9.69539312e-01, 6.65617887e-04],\n",
       "       [9.22504713e-03, 9.89662044e-01, 1.11290937e-03],\n",
       "       [5.67434689e-03, 8.37037908e-01, 1.57287745e-01],\n",
       "       [1.71163501e-02, 9.80961100e-01, 1.92254996e-03],\n",
       "       [2.32676370e-03, 6.96860673e-01, 3.00812564e-01],\n",
       "       [1.44291750e-02, 9.81543378e-01, 4.02744686e-03],\n",
       "       [1.89936972e-03, 4.95013905e-01, 5.03086725e-01],\n",
       "       [1.27141818e-02, 9.85888022e-01, 1.39779649e-03],\n",
       "       [1.37771058e-03, 4.71117351e-01, 5.27504938e-01],\n",
       "       [6.60028054e-03, 9.49834844e-01, 4.35648758e-02],\n",
       "       [9.89292374e-03, 9.88108725e-01, 1.99835087e-03],\n",
       "       [8.40272767e-03, 9.89372553e-01, 2.22471907e-03],\n",
       "       [4.23731771e-03, 9.73518608e-01, 2.22440739e-02],\n",
       "       [2.29291027e-03, 7.76901802e-01, 2.20805288e-01],\n",
       "       [5.84051754e-03, 9.23471360e-01, 7.06881226e-02],\n",
       "       [4.48899819e-02, 9.54942637e-01, 1.67381277e-04],\n",
       "       [1.45937084e-02, 9.80908152e-01, 4.49813985e-03],\n",
       "       [2.00355331e-02, 9.78444136e-01, 1.52033068e-03],\n",
       "       [1.52888644e-02, 9.82923919e-01, 1.78721616e-03],\n",
       "       [2.86061073e-04, 1.08988570e-01, 8.90725369e-01],\n",
       "       [4.93582813e-03, 7.33858699e-01, 2.61205473e-01],\n",
       "       [8.22124210e-03, 9.72079800e-01, 1.96989584e-02],\n",
       "       [5.82977697e-03, 9.83021285e-01, 1.11489384e-02],\n",
       "       [4.68313819e-03, 9.56916635e-01, 3.84002265e-02],\n",
       "       [1.38040544e-02, 9.80069615e-01, 6.12633108e-03],\n",
       "       [9.80290548e-03, 9.59254996e-01, 3.09420981e-02],\n",
       "       [7.15742339e-03, 8.85143431e-01, 1.07699146e-01],\n",
       "       [6.75010266e-03, 9.56905112e-01, 3.63447856e-02],\n",
       "       [1.22613349e-02, 9.83252927e-01, 4.48573773e-03],\n",
       "       [3.33825994e-02, 9.65294887e-01, 1.32251349e-03],\n",
       "       [9.31127477e-03, 9.57750880e-01, 3.29378452e-02],\n",
       "       [1.41584899e-02, 9.81392638e-01, 4.44887234e-03],\n",
       "       [1.13098269e-02, 9.77258358e-01, 1.14318155e-02],\n",
       "       [1.01811754e-02, 9.85815287e-01, 4.00353758e-03],\n",
       "       [6.86687793e-02, 9.31140007e-01, 1.91213643e-04],\n",
       "       [1.16732097e-02, 9.78830201e-01, 9.49658904e-03],\n",
       "       [4.61339655e-06, 3.65119151e-03, 9.96344195e-01],\n",
       "       [4.57516891e-05, 1.84582154e-02, 9.81496033e-01],\n",
       "       [1.03819183e-05, 1.11987181e-02, 9.88790900e-01],\n",
       "       [3.10564906e-05, 1.70152450e-02, 9.82953699e-01],\n",
       "       [1.01340616e-05, 7.56314092e-03, 9.92426725e-01],\n",
       "       [4.01220211e-06, 5.88247541e-03, 9.94113512e-01],\n",
       "       [1.90302738e-04, 3.86330160e-02, 9.61176681e-01],\n",
       "       [1.05386609e-05, 1.10537405e-02, 9.88935721e-01],\n",
       "       [2.08527186e-05, 1.40562422e-02, 9.85922905e-01],\n",
       "       [4.16466947e-06, 6.26274642e-03, 9.93733089e-01],\n",
       "       [5.97168097e-04, 2.81441665e-01, 7.17961167e-01],\n",
       "       [4.83902781e-05, 2.84126700e-02, 9.71538940e-01],\n",
       "       [3.60248686e-05, 2.97552939e-02, 9.70208681e-01],\n",
       "       [4.29400114e-05, 1.60961040e-02, 9.83860956e-01],\n",
       "       [1.81823395e-05, 9.22867226e-03, 9.90753145e-01],\n",
       "       [2.46375076e-05, 1.81241135e-02, 9.81851249e-01],\n",
       "       [9.67647694e-05, 5.85717485e-02, 9.41331487e-01],\n",
       "       [3.81495457e-06, 7.06156572e-03, 9.92934619e-01],\n",
       "       [1.85369214e-06, 3.00855386e-03, 9.96989592e-01],\n",
       "       [1.93755555e-04, 7.12277455e-02, 9.28578499e-01],\n",
       "       [1.06989585e-05, 1.11300238e-02, 9.88859277e-01],\n",
       "       [5.05508793e-05, 1.94097599e-02, 9.80539689e-01],\n",
       "       [4.24851830e-06, 6.33932308e-03, 9.93656428e-01],\n",
       "       [5.71186179e-04, 2.43792855e-01, 7.55635959e-01],\n",
       "       [2.56990710e-05, 2.16174352e-02, 9.78356866e-01],\n",
       "       [7.76482163e-05, 6.77859911e-02, 9.32136361e-01],\n",
       "       [9.99941302e-04, 3.59981377e-01, 6.39018682e-01],\n",
       "       [9.61671745e-04, 3.30838106e-01, 6.68200222e-01],\n",
       "       [1.57537712e-05, 1.01462350e-02, 9.89838011e-01],\n",
       "       [3.96516019e-04, 2.59913980e-01, 7.39689504e-01],\n",
       "       [1.15528562e-05, 1.41818856e-02, 9.85806562e-01],\n",
       "       [1.49551368e-04, 1.75499440e-01, 8.24351009e-01],\n",
       "       [1.30694430e-05, 8.76441137e-03, 9.91222519e-01],\n",
       "       [1.32719770e-03, 4.39204347e-01, 5.59468455e-01],\n",
       "       [8.70661260e-05, 3.25619798e-02, 9.67350954e-01],\n",
       "       [6.31085591e-06, 1.15047879e-02, 9.88488901e-01],\n",
       "       [9.53381491e-06, 7.65915375e-03, 9.92331312e-01],\n",
       "       [1.06225422e-04, 6.13540948e-02, 9.38539680e-01],\n",
       "       [1.25891430e-03, 3.87499250e-01, 6.11241836e-01],\n",
       "       [1.22629971e-04, 9.40244034e-02, 9.05852967e-01],\n",
       "       [9.02503467e-06, 8.68001540e-03, 9.91310960e-01],\n",
       "       [2.10224423e-04, 1.59449832e-01, 8.40339943e-01],\n",
       "       [4.57516891e-05, 1.84582154e-02, 9.81496033e-01],\n",
       "       [7.32996475e-06, 7.27921403e-03, 9.92713456e-01],\n",
       "       [6.67214515e-06, 7.01175854e-03, 9.92981569e-01],\n",
       "       [4.69301108e-05, 3.78469285e-02, 9.62106141e-01],\n",
       "       [1.00952508e-04, 5.46650782e-02, 9.45233969e-01],\n",
       "       [1.60773722e-04, 9.58004533e-02, 9.04038773e-01],\n",
       "       [1.71439107e-05, 1.20029529e-02, 9.87979903e-01],\n",
       "       [1.94293258e-04, 8.05051515e-02, 9.19300555e-01]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_accuracy = accuracy_score(Y, clf.predict(X))\n",
    "sk_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compare accuracy of custom and sklearn algorithm. \n",
      "\n",
      "   accuracy_custom  accuracy_sk  difference\n",
      "0         0.993333         0.98    0.013333\n"
     ]
    }
   ],
   "source": [
    "print(\"Compare accuracy of custom and sklearn algorithm. \\n\")\n",
    "res_compare_test = pd.DataFrame({'accuracy_custom' : [custom_accuracy], 'accuracy_sk' : [sk_accuracy], 'difference' : [abs(custom_accuracy - sk_accuracy)]})\n",
    "print(res_compare_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1097"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
