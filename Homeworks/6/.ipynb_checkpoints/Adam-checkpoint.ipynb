{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import sklearn.linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeuralNet class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet:\n",
    "    \"\"\"\n",
    "    NN for binary classification\n",
    "    Attributes:\n",
    "    ...\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, layers_d, normalize = True, learning_rate = 0.01, num_iter = 30000, epsilon = 1e-08, betha_1 = 0.9, betha_2 = 0.999, k = 500):\n",
    "        self.layers_d = layers_d # тут лише приховані шари а 0-го та останнього (з одним нейроном) немає\n",
    "        self.L = len(self.layers_d) + 1 # кількість шарів нейронів в мережі без урахування вихідного\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_iter = num_iter\n",
    "        self.normalize = normalize\n",
    "        self.epsilon = epsilon\n",
    "        self.betha_1 = betha_1\n",
    "        self.betha_2 = betha_2\n",
    "        self.k = k\n",
    "    \n",
    "    def __normalize(self, X, mean = None, std = None):\n",
    "        \"\"\"\n",
    "        Зверніть увагу, що нормалізація вхідних даних є дуже важливою для швидкодії нейронних мереж.\n",
    "        \"\"\"\n",
    "        '''\n",
    "        X.shape =  (n, m)\n",
    "        '''\n",
    "        n = X.shape[0]\n",
    "        m = mean\n",
    "        if m is None:\n",
    "            m = np.mean(X, axis=1).reshape((n, 1))\n",
    "            '''\n",
    "            m.shape =  (n, 1)\n",
    "            '''\n",
    "        s = std\n",
    "        if s is None:\n",
    "            s = np.std(X, axis=1).reshape((n, 1))\n",
    "            '''\n",
    "            s.shape =  (n, 1)\n",
    "            '''\n",
    "        X_new = (X - m) / s\n",
    "        return X_new, m, s\n",
    "\n",
    "    def __sigmoid(self, Z):\n",
    "        \"\"\"\n",
    "        В наступних практичних потрібно буде додати підтримку й інших активаційних функцій - це один з гіперпараметрів. \n",
    "        Їх можна вибирати для всіх шарів одночасно або мати різні активаційні функції на кожному з них.\n",
    "        \"\"\"\n",
    "        return 1 / (1 + np.exp(-Z))\n",
    "    \n",
    "    def __softmax(self, Z):\n",
    "        \n",
    "        x = np.exp(Z)        \n",
    "        '''\n",
    "        Z_i.shape  = (n_l, 1)\n",
    "        x.shape = (n_l, 1)\n",
    "        '''\n",
    "        return x / np.sum(x, axis=0, keepdims = True)\n",
    "    \n",
    "    def __initialize_parameters(self):\n",
    "        \n",
    "        self.parameters = {} \n",
    "        # стоврюємо словник зі значеннями W_i та b_i,ключами в якому будуть назви W_1, w_2, ... та b_1, b_2 і т.д\n",
    "        self.adam = {}\n",
    "        \n",
    "            \n",
    "        for i in range(1, self.L + 1):\n",
    "            \n",
    "            self.adam['VdW_' + str(i)] = 0\n",
    "            self.adam['SdW_' + str(i)] = 0\n",
    "            \n",
    "            \n",
    "            self.adam['Vdb_' + str(i)] = 0            \n",
    "            self.adam['Sdb_' + str(i)] = 0\n",
    "            self.parameters['W_' + str(i)] = np.random.randn(self.layers_d[i], self.layers_d[i - 1])* np.sqrt(2/self.layers_d[i - 1])\n",
    "            '''\n",
    "            W_i.shape  = (n_l, n_l-1) # (кількість нейронів на поточному шарі, кількість на попередньому)\n",
    "            '''\n",
    "            self.parameters['b_' + str(i)] = np.zeros((self.layers_d[i],1))\n",
    "            '''\n",
    "            b_i.shape  = (n_l,1) # (кількість нейронів на поточному шарі, 1)\n",
    "            '''\n",
    "       \n",
    "    def __forward_propagation(self, X):\n",
    "        \n",
    "        cache = {} # стоврюємо словник зі значеннями Z_i та A_i,ключами в якому будуть назви A_0, A_1, A_2, ... та Z_1, Z_2 і т.д\n",
    "        cache['A_0'] = X\n",
    "        \n",
    "        for i in range(1, self.L):\n",
    "            cache['Z_' + str(i)] = np.dot(self.parameters['W_' + str(i)], cache['A_' + str(i - 1)]) + self.parameters['b_' + str(i)]\n",
    "            '''\n",
    "            Z_i.shape  = (n_l, 1) = (n_l, n_l-1) * (n_l-1, 1) + (n_l,1)\n",
    "            '''\n",
    "            cache['A_' + str(i)] = self.__sigmoid(cache['Z_' + str(i)])\n",
    "            '''\n",
    "            A_i.shape  = (n_l, 1) = (n_l, 1)\n",
    "            '''       \n",
    "        cache['Z_' + str(self.L)] = np.dot(self.parameters['W_' + str(self.L)], cache['A_' + str(self.L - 1)]) + self.parameters['b_' + str(self.L)]\n",
    "        cache['A_' + str(self.L)] = self.__softmax(cache['Z_' + str(self.L)])\n",
    "        '''\n",
    "        функція softmax на останньому кроці \n",
    "        ''' \n",
    "        return cache['A_' + str(self.L)], cache\n",
    "    \n",
    "    def compute_cost(self, A, Y):\n",
    "        m = Y.shape[1]\n",
    "        res = Y * np.log(A) + (1 - Y) * np.log(1 - A)\n",
    "        J = -(1 / m) * np.sum(res)\n",
    "        '''\n",
    "        J.shape  = sum((1, m) x (1, m) - (1, m) x (1, m)) = sum((1, m)) = (1, 1)\n",
    "        '''\n",
    "        return J\n",
    "        \n",
    "    def __backward_propagation(self, X, Y, cache):\n",
    "        \n",
    "        m = X.shape[1]\n",
    "        gradients = {}\n",
    "        \n",
    "        gradients['dZ_' + str(self.L)] = cache['A_' + str(self.L)] - Y\n",
    "        '''\n",
    "        dZ_L.shape  = (1, m) - (1, m) = (1, m)\n",
    "        '''\n",
    "        gradients['dW_' + str(self.L)] = (1/m) * np.dot (gradients['dZ_' + str(self.L)], cache['A_' + str(self.L - 1)].T)\n",
    "        '''\n",
    "        dW_L.shape  = (1, m) * ((n_l-1, m).T) = (1, m) * (m, n_l-1) = (1, n_l-1)\n",
    "        '''\n",
    "        gradients['db_' + str(self.L)] = (1/m) * np.sum(gradients['dZ_' + str(self.L)], axis = 1, keepdims = True)\n",
    "        '''\n",
    "        db_L.shape  = sum((1, m)) = (1, 1)\n",
    "        '''\n",
    "        \n",
    "        for i in range(self.L - 1, 0, -1):\n",
    "            dA_i = np.dot (self.parameters['W_' + str(i + 1)].T, gradients['dZ_' + str(i + 1)])\n",
    "            '''\n",
    "            dA_i.shape  = (n_l-1, n_l)*(n_l, m) = (n_l-1, m)\n",
    "            '''\n",
    "            gradients['dZ_' + str(i)] = np.multiply(dA_i, cache['A_' + str(i)] * (1 - cache['A_' + str(i)]))\n",
    "            '''\n",
    "            dZ_i.shape  = (n_l, m)x(n_l, m) = (n_l, m)\n",
    "            '''\n",
    "            gradients['dW_' + str(i)] = (1/m) * np.dot (gradients['dZ_' + str(i)], cache['A_' + str(i - 1)].T)\n",
    "            '''\n",
    "            dW_i.shape  = (n_l, m)*((n_l-1, n).T) = (n_l, m)*(m, n_l-1) = (n_l, n_l-1)\n",
    "            '''\n",
    "            gradients['db_' + str(i)] = (1/m) * np.sum(gradients['dZ_' + str(i)], axis = 1, keepdims = True)\n",
    "            '''\n",
    "            db_i.shape = sum((n_l, m)) = (n_l, 1)\n",
    "            '''       \n",
    "        \n",
    "        return gradients\n",
    "    \n",
    "    def __update_parameters(self, gradients, t):\n",
    "          \n",
    "        for i in range(1, self.L + 1):            \n",
    "            \n",
    "            self.adam['VdW_' + str(i)] = self.betha_1 * self.adam['VdW_' + str(i)] + (1 - self.betha_1) * gradients['dW_' + str(i)]  \n",
    "            self.adam['SdW_' + str(i)] = self.betha_2 * self.adam['SdW_' + str(i)] + (1 - self.betha_2) * (gradients['dW_' + str(i)]**2)\n",
    "            \n",
    "            self.adam['VdW_corr_' + str(i)] = self.adam['VdW_' + str(i)] / (1 - self.betha_1**(t + 1))\n",
    "            self.adam['SdW_corr_' + str(i)] = self.adam['SdW_' + str(i)] / (1 - self.betha_2**(t + 1))\n",
    "            \n",
    "            self.parameters['W_' + str(i)] = self.parameters['W_' + str(i)] - (self.learning_rate * self.adam['VdW_corr_' + str(i)] ) /(self.adam['SdW_corr_' + str(i)]**(0.5) + self.epsilon)\n",
    "            '''\n",
    "            #W_i.shape  = (n_l, n_l-1) # (кількість нейронів на поточному шарі, кількість на попередньому)\n",
    "            '''\n",
    "\n",
    "            self.adam['Vdb_' + str(i)] =  self.betha_1 * self.adam['Vdb_' + str(i)] + (1 - self.betha_1) * gradients['db_' + str(i)]  \n",
    "            self.adam['Sdb_' + str(i)] =  self.betha_2 * self.adam['Sdb_' + str(i)] + (1 - self.betha_2) * (gradients['db_' + str(i)]**2)          \n",
    "            \n",
    "            self.adam['Vdb_corr_' + str(i)] = self.adam['Vdb_' + str(i)] / (1 - self.betha_1**(t + 1))        \n",
    "            self.adam['Sdb_corr_' + str(i)] = self.adam['Sdb_' + str(i)] / (1 - self.betha_2**(t + 1))\n",
    "\n",
    "            self.parameters['b_' + str(i)] = self.parameters['b_' + str(i)] - (self.learning_rate * self.adam['Vdb_corr_' + str(i)]) / (self.adam['Sdb_corr_' + str(i)]**(0.5) + self.epsilon)\n",
    "            \n",
    "            '''\n",
    "            #b_i.shape  = (n_l,1) # (кількість нейронів на поточному шарі, 1)\n",
    "            '''\n",
    "            \n",
    "           \n",
    "            '''\n",
    "            self.parameters['W_' + str(i)] -= self.learning_rate * gradients['dW_' + str(i)]\n",
    "            self.parameters['b_' + str(i)] -= self.learning_rate * gradients['db_' + str(i)]\n",
    "         '''\n",
    "           \n",
    "        \n",
    "    \n",
    "    def fit(self, X_vert, Y_vert, print_cost = True):\n",
    "        X= X_vert.T\n",
    "        \n",
    "        n_x = X.shape[0] # визначаємо кількість нейронів у вихідному шарі\n",
    "                \n",
    "        lb = LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False) \n",
    "        # задаємо перетворення приналежності до класів як 0 і 1 відвідно для кожного прикладу \n",
    "        #([0, 0, 1] - приклад з класу 2, [1, 0, 0] - приклад з класу 0, [0, 1, 0] - приклад з класу 1)\n",
    "        lb.fit(Y_vert)\n",
    "        \n",
    "        Y = lb.transform(Y_vert).T        \n",
    "        final_classes = Y.shape[0] # визначаємо кількість нейронів у вихідному шарі\n",
    "        \n",
    "        self.layers_d.insert(0, n_x)\n",
    "        self.layers_d.append(final_classes) \n",
    "        '''\n",
    "        додаємо вхідний та вихідний шари до прихованих \n",
    "        і отримуємо клькість всіх шарів нейронної мережі і кількість нейронів на кожному шарі\n",
    "        '''\n",
    "        \n",
    "        if self.normalize:\n",
    "            X, self.__mean, self.__std = self.__normalize(X)\n",
    "        \n",
    "        costs = []\n",
    "        \n",
    "        m = X.shape[1]\n",
    "        n_x = X.shape[0]\n",
    "        \n",
    "        self.__initialize_parameters()\n",
    "        \n",
    "        previous_cost = 0;\n",
    "\n",
    "        for i in range(self.num_iter):\n",
    "            \n",
    "            A, cache = self.__forward_propagation(X)\n",
    "\n",
    "            cost = self.compute_cost(A, Y)\n",
    "\n",
    "            gradients = self.__backward_propagation(X, Y, cache)\n",
    "\n",
    "            self.__update_parameters(gradients, i)\n",
    "\n",
    "            if print_cost and i % 100 == 0:\n",
    "                print(\"{}-th iteration: {}\".format(i, cost))\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                costs.append(cost)\n",
    "            if (abs(previous_cost - cost) < self.epsilon):\n",
    "                k = k - 1\n",
    "                if (k == 0):\n",
    "                    break;\n",
    "                    \n",
    "            previous_cost = cost\n",
    "\n",
    "        if print_cost:\n",
    "            plt.plot(costs)\n",
    "            plt.ylabel(\"Cost\")\n",
    "            plt.xlabel(\"Iteration, *100\")\n",
    "            plt.show()  \n",
    "            \n",
    "           \n",
    "    def predict_proba(self, X_vert):\n",
    "        X = X_vert.T\n",
    "        if self.normalize:\n",
    "            X, _, _ = self.__normalize(X, self.__mean, self.__std)    \n",
    "        \n",
    "        probs = self.__forward_propagation(X)[0]\n",
    "        return probs.T\n",
    "    \n",
    "    def predict(self, X_vert):\n",
    "        probs = self.predict_proba(X_vert)\n",
    "        results_bin = (probs == probs.max(axis=1)[:, None]).astype(int)\n",
    "        '''\n",
    "        максимальне значення в кожному рядку перетворюємо на 1 а інші задаємо як 0\n",
    "        наприклад, \n",
    "        a = np.array([[0, 1], [2, 2], [4, 3]])\n",
    "        (a == a.max(axis=1)[:,None]).astype(int)\n",
    "        \n",
    "        Результат : \n",
    "        array([[0, 1], [1, 1], [1, 0]])\n",
    "        '''\n",
    "        return results_bin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "X, Y = load_iris(return_X_y = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "lb = LabelBinarizer(sparse_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = lb.fit(Y) # перетворюємо значення Y масив значеннь з 0 та 1, де 1 - приналежність до відповідного по порядку класу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb.transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = NeuralNet([4, 3, 3],normalize = True, learning_rate = 0.05, betha_1 = 0.9, betha_2 = 0.999, num_iter = 10000, epsilon = 1e-08, k = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-th iteration: 1.9339336952008588\n",
      "100-th iteration: 0.15057308677212072\n",
      "200-th iteration: 0.08622674894940152\n",
      "300-th iteration: 0.07731591482249207\n",
      "400-th iteration: 0.0719458398257185\n",
      "500-th iteration: 0.0695393267431875\n",
      "600-th iteration: 0.06827141731305736\n",
      "700-th iteration: 0.06752617826989392\n",
      "800-th iteration: 0.06704935638533395\n",
      "900-th iteration: 0.06672327148136067\n",
      "1000-th iteration: 0.06648627490632604\n",
      "1100-th iteration: 0.06630192402950547\n",
      "1200-th iteration: 0.06613887660754156\n",
      "1300-th iteration: 0.06564812100603035\n",
      "1400-th iteration: 0.03275423241049084\n",
      "1500-th iteration: 0.0012661629762523755\n",
      "1600-th iteration: 0.0007712428504267301\n",
      "1700-th iteration: 0.0005644733021394673\n",
      "1800-th iteration: 0.0004465373668560748\n",
      "1900-th iteration: 0.00036871048069811604\n",
      "2000-th iteration: 0.00031281481954060933\n",
      "2100-th iteration: 0.00027040541665750617\n",
      "2200-th iteration: 0.00023697373920008436\n",
      "2300-th iteration: 0.00020986841598535875\n",
      "2400-th iteration: 0.000187415212954453\n",
      "2500-th iteration: 0.00016849774249882554\n",
      "2600-th iteration: 0.00015233895643058408\n",
      "2700-th iteration: 0.0001383789707485086\n",
      "2800-th iteration: 0.00012620276839494604\n",
      "2900-th iteration: 0.00011549538255905226\n",
      "3000-th iteration: 0.00010601302402982701\n",
      "3100-th iteration: 9.756387029605057e-05\n",
      "3200-th iteration: 8.99949227207156e-05\n",
      "3300-th iteration: 8.31827763024939e-05\n",
      "3400-th iteration: 7.70269456234668e-05\n",
      "3500-th iteration: 7.144486185097052e-05\n",
      "3600-th iteration: 6.636797398998031e-05\n",
      "3700-th iteration: 6.173864120374963e-05\n",
      "3800-th iteration: 5.750769553761858e-05\n",
      "3900-th iteration: 5.363263639082636e-05\n",
      "4000-th iteration: 5.007637953159984e-05\n",
      "4100-th iteration: 4.680640696010594e-05\n",
      "4200-th iteration: 4.379414642432562e-05\n",
      "4300-th iteration: 4.101446187858648e-05\n",
      "4400-th iteration: 3.8445203320245814e-05\n",
      "4500-th iteration: 3.6066804811239174e-05\n",
      "4600-th iteration: 3.386193163906593e-05\n",
      "4700-th iteration: 3.181517646928114e-05\n",
      "4800-th iteration: 2.991280090949453e-05\n",
      "4900-th iteration: 2.814251688540161e-05\n",
      "5000-th iteration: 2.6493301777009925e-05\n",
      "5100-th iteration: 2.4955241695622013e-05\n",
      "5200-th iteration: 2.351939805195006e-05\n",
      "5300-th iteration: 2.2177693381846844e-05\n",
      "5400-th iteration: 2.0922813134366047e-05\n",
      "5500-th iteration: 1.9748120753150593e-05\n",
      "5600-th iteration: 1.864758389250888e-05\n",
      "5700-th iteration: 1.7615710019572094e-05\n",
      "5800-th iteration: 1.664748998094899e-05\n",
      "5900-th iteration: 1.573834836958305e-05\n",
      "6000-th iteration: 1.488409973333812e-05\n",
      "6100-th iteration: 1.4080909828756648e-05\n",
      "6200-th iteration: 1.3325261253554142e-05\n",
      "6300-th iteration: 1.2613922895590981e-05\n",
      "6400-th iteration: 1.1943922721142485e-05\n",
      "6500-th iteration: 1.1312523493610446e-05\n",
      "6600-th iteration: 1.071720107168079e-05\n",
      "6700-th iteration: 1.0155624983033544e-05\n",
      "6800-th iteration: 9.625641009812548e-06\n",
      "6900-th iteration: 9.125255555848635e-06\n",
      "7000-th iteration: 8.65262159452445e-06\n",
      "7100-th iteration: 8.206026020824292e-06\n",
      "7200-th iteration: 7.783878252844952e-06\n",
      "7300-th iteration: 7.384699945839734e-06\n",
      "7400-th iteration: 7.007115698994113e-06\n",
      "7500-th iteration: 6.649844648163386e-06\n",
      "7600-th iteration: 6.311692850886075e-06\n",
      "7700-th iteration: 5.991546380374607e-06\n",
      "7800-th iteration: 5.688365054534724e-06\n",
      "7900-th iteration: 5.401176734810666e-06\n",
      "8000-th iteration: 5.129072136603999e-06\n",
      "8100-th iteration: 4.87120009960626e-06\n",
      "8200-th iteration: 4.62676327202125e-06\n",
      "8300-th iteration: 4.395014167735308e-06\n",
      "8400-th iteration: 4.1752515598042356e-06\n",
      "8500-th iteration: 3.966817177993358e-06\n",
      "8600-th iteration: 3.7690926805712998e-06\n",
      "8700-th iteration: 3.581496875181655e-06\n",
      "8800-th iteration: 3.4034831645810418e-06\n",
      "8900-th iteration: 3.2345371970011933e-06\n",
      "9000-th iteration: 3.074174701959697e-06\n",
      "9100-th iteration: 2.9219394951147443e-06\n",
      "9200-th iteration: 2.777401636388695e-06\n",
      "9300-th iteration: 2.640155728516471e-06\n",
      "9400-th iteration: 2.5098193429693066e-06\n",
      "9500-th iteration: 2.3860315629156905e-06\n",
      "9600-th iteration: 2.2684516324929552e-06\n",
      "9700-th iteration: 2.1567577041795864e-06\n",
      "9800-th iteration: 2.050645675322765e-06\n",
      "9900-th iteration: 1.949828106893382e-06\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cls.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_1 \t \n",
      " [[ 0.42096548  0.02832493 -1.74304268 -1.40673527]\n",
      " [ 0.1646274  -0.22915548  0.61383481  1.32719409]\n",
      " [ 0.0345421   1.06792305 -0.73933813 -1.15012744]\n",
      " [ 0.09072316 -1.07202095  1.19234381  0.46793846]] \n",
      "b_1 \t \n",
      " [[ 1.6383847 ]\n",
      " [-1.05949738]\n",
      " [-0.0575845 ]\n",
      " [ 0.15363748]] \n",
      "W_2 \t \n",
      " [[-0.99929566  1.91566121 -1.9243991   2.30428728]\n",
      " [-0.13173216 -1.77845666 -1.33460978 -0.25884256]\n",
      " [ 4.90820833 -2.32869112  1.94578948 -0.8990321 ]] \n",
      "b_2 \t \n",
      " [[ 0.69712658]\n",
      " [ 0.05946827]\n",
      " [-0.40292544]] \n",
      "W_3 \t \n",
      " [[-0.90511211 -1.27902624 -1.44098275]\n",
      " [ 4.77354744  0.44038879 -4.92038634]\n",
      " [-2.09320799  0.65132462  5.16343452]] \n",
      "b_3 \t \n",
      " [[ 0.45531686]\n",
      " [ 1.49053704]\n",
      " [-0.61085005]] \n",
      "W_4 \t \n",
      " [[ 0.14866251 -9.50758242  3.4994905 ]\n",
      " [-1.00864625  1.38732797  3.05697868]\n",
      " [ 0.78796303  7.39931314 -4.88595402]] \n",
      "b_4 \t \n",
      " [[ 3.09196565]\n",
      " [-0.65084013]\n",
      " [-2.44112552]] \n"
     ]
    }
   ],
   "source": [
    "for parameter in cls.parameters:\n",
    "    print(\"{} \\t \\n {} \".format(parameter, cls.parameters[parameter])) #cls.parameters[parameter].shape \\t {} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.77870598e-01, 2.21264365e-02, 2.96511508e-06],\n",
       "       [9.75026218e-01, 2.49702380e-02, 3.54438833e-06],\n",
       "       [9.76868092e-01, 2.31287453e-02, 3.16278479e-06],\n",
       "       [9.75850521e-01, 2.41461081e-02, 3.37129928e-06],\n",
       "       [9.78094586e-01, 2.19024928e-02, 2.92090507e-06],\n",
       "       [9.78226336e-01, 2.17707647e-02, 2.89925238e-06],\n",
       "       [9.77433878e-01, 2.25630709e-02, 3.05073685e-06],\n",
       "       [9.77503284e-01, 2.24936783e-02, 3.03788986e-06],\n",
       "       [9.73789532e-01, 2.62066619e-02, 3.80586004e-06],\n",
       "       [9.76186711e-01, 2.38099862e-02, 3.30312171e-06],\n",
       "       [9.78204134e-01, 2.17929654e-02, 2.90062620e-06],\n",
       "       [9.77427331e-01, 2.25696164e-02, 3.05284099e-06],\n",
       "       [9.75546777e-01, 2.44497890e-02, 3.43447641e-06],\n",
       "       [9.76251907e-01, 2.37448084e-02, 3.28453422e-06],\n",
       "       [9.78589658e-01, 2.14075172e-02, 2.82499888e-06],\n",
       "       [9.78654479e-01, 2.13427066e-02, 2.81441556e-06],\n",
       "       [9.78370039e-01, 2.16270917e-02, 2.86967600e-06],\n",
       "       [9.77723931e-01, 2.22730739e-02, 2.99496375e-06],\n",
       "       [9.78163947e-01, 2.18331416e-02, 2.91100203e-06],\n",
       "       [9.78272667e-01, 2.17244455e-02, 2.88754321e-06],\n",
       "       [9.77271533e-01, 2.27253804e-02, 3.08649637e-06],\n",
       "       [9.77999118e-01, 2.19979396e-02, 2.94239506e-06],\n",
       "       [9.78283334e-01, 2.17137841e-02, 2.88218241e-06],\n",
       "       [9.75741596e-01, 2.42550024e-02, 3.40155063e-06],\n",
       "       [9.77108394e-01, 2.28884878e-02, 3.11822813e-06],\n",
       "       [9.74387104e-01, 2.56092126e-02, 3.68322498e-06],\n",
       "       [9.76947325e-01, 2.30495232e-02, 3.15176145e-06],\n",
       "       [9.77797456e-01, 2.21995643e-02, 2.98019563e-06],\n",
       "       [9.77573748e-01, 2.24232282e-02, 3.02405824e-06],\n",
       "       [9.76418061e-01, 2.35786828e-02, 3.25589172e-06],\n",
       "       [9.75590974e-01, 2.44055985e-02, 3.42705521e-06],\n",
       "       [9.77026534e-01, 2.29703290e-02, 3.13692750e-06],\n",
       "       [9.78650595e-01, 2.13465927e-02, 2.81198631e-06],\n",
       "       [9.78670635e-01, 2.13265565e-02, 2.80896295e-06],\n",
       "       [9.75796456e-01, 2.42001603e-02, 3.38402081e-06],\n",
       "       [9.76964165e-01, 2.30326906e-02, 3.14403016e-06],\n",
       "       [9.77908156e-01, 2.20888855e-02, 2.95838622e-06],\n",
       "       [9.78198111e-01, 2.17989897e-02, 2.89971636e-06],\n",
       "       [9.75395902e-01, 2.46006348e-02, 3.46302850e-06],\n",
       "       [9.77495073e-01, 2.25018873e-02, 3.03983328e-06],\n",
       "       [9.77800871e-01, 2.21961504e-02, 2.97907159e-06],\n",
       "       [9.02796395e-01, 9.71743916e-02, 2.92131102e-05],\n",
       "       [9.76899655e-01, 2.30971893e-02, 3.15532669e-06],\n",
       "       [9.76869416e-01, 2.31274128e-02, 3.17095583e-06],\n",
       "       [9.77974406e-01, 2.20226448e-02, 2.94895923e-06],\n",
       "       [9.74451879e-01, 2.55444551e-02, 3.66608211e-06],\n",
       "       [9.78319861e-01, 2.16772610e-02, 2.87761007e-06],\n",
       "       [9.76741341e-01, 2.32554703e-02, 3.18854403e-06],\n",
       "       [9.78208585e-01, 2.17885157e-02, 2.89953746e-06],\n",
       "       [9.77207160e-01, 2.27897436e-02, 3.09642239e-06],\n",
       "       [2.22490282e-02, 9.65867465e-01, 1.18835071e-02],\n",
       "       [1.59168278e-02, 9.68179931e-01, 1.59032411e-02],\n",
       "       [4.91260112e-03, 9.47297802e-01, 4.77895968e-02],\n",
       "       [5.25579841e-03, 9.58588978e-01, 3.61552238e-02],\n",
       "       [3.42362579e-03, 9.25657666e-01, 7.09187086e-02],\n",
       "       [6.91161176e-03, 9.63103361e-01, 2.99850269e-02],\n",
       "       [7.13511023e-03, 9.57465384e-01, 3.53995062e-02],\n",
       "       [3.55564149e-02, 9.57230606e-01, 7.21297928e-03],\n",
       "       [1.10965186e-02, 9.69524594e-01, 1.93788869e-02],\n",
       "       [8.47493350e-03, 9.67442588e-01, 2.40824784e-02],\n",
       "       [1.18392709e-02, 9.72511894e-01, 1.56488354e-02],\n",
       "       [1.04941460e-02, 9.67997330e-01, 2.15085236e-02],\n",
       "       [1.15624518e-02, 9.72100747e-01, 1.63368013e-02],\n",
       "       [4.59976115e-03, 9.46375551e-01, 4.90246882e-02],\n",
       "       [7.60774775e-02, 9.19451855e-01, 4.47066782e-03],\n",
       "       [2.49161462e-02, 9.64435396e-01, 1.06484580e-02],\n",
       "       [4.41271327e-03, 9.40760176e-01, 5.48271105e-02],\n",
       "       [3.91755201e-02, 9.53820434e-01, 7.00404612e-03],\n",
       "       [1.62407972e-03, 7.69525643e-01, 2.28850277e-01],\n",
       "       [1.71243887e-02, 9.70378955e-01, 1.24966567e-02],\n",
       "       [8.26452196e-04, 4.74627090e-01, 5.24546458e-01],\n",
       "       [2.04914053e-02, 9.67948163e-01, 1.15604315e-02],\n",
       "       [1.10048072e-03, 6.08911643e-01, 3.89987876e-01],\n",
       "       [8.84490975e-03, 9.67862463e-01, 2.32926269e-02],\n",
       "       [1.87143776e-02, 9.68643138e-01, 1.26424844e-02],\n",
       "       [1.49025017e-02, 9.69528885e-01, 1.55686132e-02],\n",
       "       [4.17911638e-03, 9.42624925e-01, 5.31959588e-02],\n",
       "       [9.63251031e-04, 5.41915279e-01, 4.57121470e-01],\n",
       "       [4.06547158e-03, 9.38030034e-01, 5.79044940e-02],\n",
       "       [6.52002610e-02, 9.30014942e-01, 4.78479721e-03],\n",
       "       [1.47929425e-02, 9.71422052e-01, 1.37850058e-02],\n",
       "       [2.23248580e-02, 9.67610160e-01, 1.00649822e-02],\n",
       "       [2.39039920e-02, 9.66010478e-01, 1.00855305e-02],\n",
       "       [3.10210623e-04, 2.16316170e-01, 7.83373620e-01],\n",
       "       [3.95478388e-03, 9.32171366e-01, 6.38738505e-02],\n",
       "       [2.18491649e-02, 9.64522743e-01, 1.36280920e-02],\n",
       "       [6.92719788e-03, 9.60483148e-01, 3.25896546e-02],\n",
       "       [4.13084232e-03, 9.46778027e-01, 4.90911309e-02],\n",
       "       [4.13340225e-02, 9.51448933e-01, 7.21704416e-03],\n",
       "       [7.29438867e-03, 9.66384178e-01, 2.63214337e-02],\n",
       "       [7.02825494e-03, 9.65105344e-01, 2.78664008e-02],\n",
       "       [7.82846169e-03, 9.64036496e-01, 2.81350418e-02],\n",
       "       [1.44889348e-02, 9.70974711e-01, 1.45363542e-02],\n",
       "       [2.55943597e-02, 9.65401481e-01, 9.00415914e-03],\n",
       "       [8.79982941e-03, 9.68192266e-01, 2.30079047e-02],\n",
       "       [6.05618845e-02, 9.34037021e-01, 5.40109421e-03],\n",
       "       [1.91029683e-02, 9.68299276e-01, 1.25977560e-02],\n",
       "       [1.78101748e-02, 9.69003321e-01, 1.31865039e-02],\n",
       "       [6.08511528e-02, 9.34167079e-01, 4.98176801e-03],\n",
       "       [1.53872585e-02, 9.70053664e-01, 1.45590779e-02],\n",
       "       [2.08213953e-05, 1.68757494e-02, 9.83103429e-01],\n",
       "       [4.50008732e-05, 3.62470848e-02, 9.63707914e-01],\n",
       "       [2.61361096e-05, 2.12176071e-02, 9.78756257e-01],\n",
       "       [4.74027786e-05, 3.79819076e-02, 9.61970690e-01],\n",
       "       [2.34028788e-05, 1.90332912e-02, 9.80943306e-01],\n",
       "       [2.19458302e-05, 1.78210548e-02, 9.82156999e-01],\n",
       "       [2.09166001e-04, 1.53094535e-01, 8.46696299e-01],\n",
       "       [3.11530680e-05, 2.52631552e-02, 9.74705692e-01],\n",
       "       [3.28004036e-05, 2.66705336e-02, 9.73296666e-01],\n",
       "       [2.28726243e-05, 1.84284459e-02, 9.81548681e-01],\n",
       "       [9.82208866e-05, 7.46027772e-02, 9.25299002e-01],\n",
       "       [4.40874797e-05, 3.54638977e-02, 9.64492015e-01],\n",
       "       [3.15006647e-05, 2.54883759e-02, 9.74480123e-01],\n",
       "       [3.29944321e-05, 2.68661181e-02, 9.73100887e-01],\n",
       "       [2.25697512e-05, 1.83817351e-02, 9.81595695e-01],\n",
       "       [2.78891595e-05, 2.25640276e-02, 9.77408083e-01],\n",
       "       [7.29763322e-05, 5.69907800e-02, 9.42936244e-01],\n",
       "       [2.82514226e-05, 2.25301737e-02, 9.77441575e-01],\n",
       "       [1.94036875e-05, 1.57360576e-02, 9.84244539e-01],\n",
       "       [3.66719142e-04, 2.52671610e-01, 7.46961671e-01],\n",
       "       [2.46573919e-05, 1.99788793e-02, 9.79996463e-01],\n",
       "       [4.36994138e-05, 3.51917066e-02, 9.64764594e-01],\n",
       "       [2.20714195e-05, 1.79447290e-02, 9.82033200e-01],\n",
       "       [1.69870687e-04, 1.25406519e-01, 8.74423611e-01],\n",
       "       [3.35076876e-05, 2.69327094e-02, 9.73033783e-01],\n",
       "       [5.88528815e-05, 4.62517182e-02, 9.53689429e-01],\n",
       "       [2.75540716e-04, 1.93602536e-01, 8.06121923e-01],\n",
       "       [3.19191372e-04, 2.18936910e-01, 7.80743899e-01],\n",
       "       [2.54871375e-05, 2.07608194e-02, 9.79213693e-01],\n",
       "       [2.23698032e-04, 1.59702936e-01, 8.40073366e-01],\n",
       "       [2.96151790e-05, 2.40370705e-02, 9.75933314e-01],\n",
       "       [6.91016267e-05, 5.24596337e-02, 9.47471265e-01],\n",
       "       [2.34344101e-05, 1.90847827e-02, 9.80891783e-01],\n",
       "       [1.16702722e-03, 6.26741878e-01, 3.72091095e-01],\n",
       "       [2.49148829e-04, 1.78775149e-01, 8.20975702e-01],\n",
       "       [2.22264209e-05, 1.80304768e-02, 9.81947297e-01],\n",
       "       [2.45758695e-05, 1.98645986e-02, 9.80110826e-01],\n",
       "       [8.48024359e-05, 6.54272101e-02, 9.34487987e-01],\n",
       "       [4.17316000e-04, 2.76299438e-01, 7.23283246e-01],\n",
       "       [3.85815996e-05, 3.09589040e-02, 9.69002514e-01],\n",
       "       [2.25806029e-05, 1.83262240e-02, 9.81651195e-01],\n",
       "       [3.29423324e-05, 2.65473933e-02, 9.73419664e-01],\n",
       "       [4.50008732e-05, 3.62470848e-02, 9.63707914e-01],\n",
       "       [2.30046649e-05, 1.86571431e-02, 9.81319852e-01],\n",
       "       [2.20665838e-05, 1.78705934e-02, 9.82107340e-01],\n",
       "       [2.76929182e-05, 2.24502848e-02, 9.77522022e-01],\n",
       "       [5.56997679e-05, 4.43985501e-02, 9.55545750e-01],\n",
       "       [5.25848565e-05, 4.17530657e-02, 9.58194349e-01],\n",
       "       [2.98399617e-05, 2.40103193e-02, 9.75959841e-01],\n",
       "       [1.31579563e-04, 9.86434454e-02, 9.01224975e-01]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_prob = cls.predict_proba(X)\n",
    "Y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "Y_hat = cls.predict(X) # отримуємо масив з 0 та 1 \n",
    "Y_hat = np.array(lb.inverse_transform(Y_hat)) # перетворюємо в значення класу, до якого належить приклад\n",
    "print(Y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_accuracy = accuracy_score(Y, Y_hat)\n",
    "custom_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-learn Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(hidden_layer_sizes = (20,), max_iter = 10000,  solver = 'adam') #, activation = 'logistic', solver = 'sgd', learning_rate_init = 0.01, learning_rate = 'constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(20,), max_iter=10000)"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.93854692e-01, 6.14508225e-03, 2.25512666e-07],\n",
       "       [9.84630633e-01, 1.53680693e-02, 1.29727053e-06],\n",
       "       [9.90968229e-01, 9.03106063e-03, 7.10404384e-07],\n",
       "       [9.83194735e-01, 1.68031147e-02, 2.15044885e-06],\n",
       "       [9.94300661e-01, 5.69911404e-03, 2.25069090e-07],\n",
       "       [9.92304218e-01, 7.69550828e-03, 2.73659899e-07],\n",
       "       [9.90504357e-01, 9.49467488e-03, 9.68515937e-07],\n",
       "       [9.90819342e-01, 9.18017410e-03, 4.83973515e-07],\n",
       "       [9.80794539e-01, 1.92019565e-02, 3.50443474e-06],\n",
       "       [9.85687834e-01, 1.43111690e-02, 9.96911115e-07],\n",
       "       [9.94982448e-01, 5.01744297e-03, 1.09276534e-07],\n",
       "       [9.87521865e-01, 1.24771286e-02, 1.00635797e-06],\n",
       "       [9.86593793e-01, 1.34051726e-02, 1.03448874e-06],\n",
       "       [9.90899556e-01, 9.09936402e-03, 1.08047122e-06],\n",
       "       [9.98395627e-01, 1.60436262e-03, 1.02553826e-08],\n",
       "       [9.98029489e-01, 1.97049036e-03, 2.09285600e-08],\n",
       "       [9.97084183e-01, 2.91575639e-03, 6.02498172e-08],\n",
       "       [9.93354233e-01, 6.64547536e-03, 2.91729890e-07],\n",
       "       [9.92049075e-01, 7.95075125e-03, 1.73999045e-07],\n",
       "       [9.94587325e-01, 5.41247155e-03, 2.03113867e-07],\n",
       "       [9.84769794e-01, 1.52295605e-02, 6.45296960e-07],\n",
       "       [9.93121772e-01, 6.87788392e-03, 3.44190334e-07],\n",
       "       [9.96822658e-01, 3.17718869e-03, 1.53157047e-07],\n",
       "       [9.71266592e-01, 2.87294874e-02, 3.92099954e-06],\n",
       "       [9.73291329e-01, 2.67053457e-02, 3.32485192e-06],\n",
       "       [9.74149833e-01, 2.58475798e-02, 2.58721656e-06],\n",
       "       [9.84070632e-01, 1.59278548e-02, 1.51284569e-06],\n",
       "       [9.92531763e-01, 7.46796867e-03, 2.68689234e-07],\n",
       "       [9.93049885e-01, 6.94987200e-03, 2.43330521e-07],\n",
       "       [9.82063339e-01, 1.79345891e-02, 2.07185198e-06],\n",
       "       [9.78394604e-01, 2.16029172e-02, 2.47857755e-06],\n",
       "       [9.88065998e-01, 1.19334213e-02, 5.80833105e-07],\n",
       "       [9.96848169e-01, 3.15177429e-03, 5.71340348e-08],\n",
       "       [9.97933402e-01, 2.06657552e-03, 2.29254268e-08],\n",
       "       [9.83495277e-01, 1.65032918e-02, 1.43156087e-06],\n",
       "       [9.93572211e-01, 6.42750552e-03, 2.83093515e-07],\n",
       "       [9.95527689e-01, 4.47222935e-03, 8.13664248e-08],\n",
       "       [9.94324337e-01, 5.67544025e-03, 2.22456253e-07],\n",
       "       [9.86483404e-01, 1.35145993e-02, 1.99710274e-06],\n",
       "       [9.90874752e-01, 9.12482523e-03, 4.22566637e-07],\n",
       "       [9.94387929e-01, 5.61181639e-03, 2.54781966e-07],\n",
       "       [9.47210956e-01, 5.27701041e-02, 1.89394030e-05],\n",
       "       [9.89483663e-01, 1.05150186e-02, 1.31860118e-06],\n",
       "       [9.82535193e-01, 1.74625327e-02, 2.27477035e-06],\n",
       "       [9.83830545e-01, 1.61681600e-02, 1.29466993e-06],\n",
       "       [9.82172157e-01, 1.78257094e-02, 2.13312352e-06],\n",
       "       [9.93763383e-01, 6.23639611e-03, 2.20987560e-07],\n",
       "       [9.88442274e-01, 1.15565462e-02, 1.18024706e-06],\n",
       "       [9.94750796e-01, 5.24907119e-03, 1.33129204e-07],\n",
       "       [9.91455247e-01, 8.54431448e-03, 4.38348884e-07],\n",
       "       [3.11416626e-03, 9.86383549e-01, 1.05022852e-02],\n",
       "       [5.78917168e-03, 9.63826818e-01, 3.03840107e-02],\n",
       "       [2.50304187e-03, 9.42105372e-01, 5.53915864e-02],\n",
       "       [6.08690766e-03, 8.71257052e-01, 1.22656040e-01],\n",
       "       [3.08991804e-03, 9.08122835e-01, 8.87872466e-02],\n",
       "       [5.57593430e-03, 8.40512130e-01, 1.53911936e-01],\n",
       "       [5.57288216e-03, 8.98492695e-01, 9.59344230e-02],\n",
       "       [3.59135160e-02, 9.47383146e-01, 1.67033375e-02],\n",
       "       [3.28548864e-03, 9.72467849e-01, 2.42466625e-02],\n",
       "       [1.29636963e-02, 8.86291611e-01, 1.00744693e-01],\n",
       "       [1.06975217e-02, 9.52853750e-01, 3.64487278e-02],\n",
       "       [8.67376120e-03, 9.42249580e-01, 4.90766586e-02],\n",
       "       [4.47443185e-03, 9.78302828e-01, 1.72227404e-02],\n",
       "       [3.90106214e-03, 8.37963378e-01, 1.58135560e-01],\n",
       "       [2.92815365e-02, 9.59528025e-01, 1.11904386e-02],\n",
       "       [4.81990513e-03, 9.86225410e-01, 8.95468439e-03],\n",
       "       [6.70725540e-03, 7.38551351e-01, 2.54741394e-01],\n",
       "       [8.25066411e-03, 9.79395139e-01, 1.23541968e-02],\n",
       "       [1.58765962e-03, 6.30101651e-01, 3.68310689e-01],\n",
       "       [8.30814348e-03, 9.72510584e-01, 1.91812724e-02],\n",
       "       [3.19330686e-03, 4.39998637e-01, 5.56808056e-01],\n",
       "       [8.65557178e-03, 9.79041273e-01, 1.23031556e-02],\n",
       "       [1.10712248e-03, 4.84324289e-01, 5.14568588e-01],\n",
       "       [3.68757294e-03, 9.06114162e-01, 9.01982647e-02],\n",
       "       [4.95773510e-03, 9.82870052e-01, 1.21722132e-02],\n",
       "       [4.39817405e-03, 9.81985545e-01, 1.36162807e-02],\n",
       "       [2.10806529e-03, 9.34856409e-01, 6.30355256e-02],\n",
       "       [1.85544386e-03, 6.96563410e-01, 3.01581146e-01],\n",
       "       [5.11796723e-03, 8.50319113e-01, 1.44562920e-01],\n",
       "       [3.30800724e-02, 9.60580252e-01, 6.33967545e-03],\n",
       "       [8.76972216e-03, 9.70213567e-01, 2.10167108e-02],\n",
       "       [1.30725563e-02, 9.72572458e-01, 1.43549858e-02],\n",
       "       [1.05200431e-02, 9.75348418e-01, 1.41315394e-02],\n",
       "       [5.50957081e-04, 1.80537474e-01, 8.18911569e-01],\n",
       "       [6.76933811e-03, 6.38670081e-01, 3.54560581e-01],\n",
       "       [9.37568093e-03, 9.19005134e-01, 7.16191852e-02],\n",
       "       [3.48832032e-03, 9.55253213e-01, 4.12584663e-02],\n",
       "       [2.46059440e-03, 9.06272977e-01, 9.12664287e-02],\n",
       "       [1.22702256e-02, 9.57183342e-01, 3.05464324e-02],\n",
       "       [7.82966307e-03, 9.13308377e-01, 7.88619595e-02],\n",
       "       [5.54393726e-03, 8.22780094e-01, 1.71675969e-01],\n",
       "       [5.06256636e-03, 9.04614244e-01, 9.03231895e-02],\n",
       "       [7.20503269e-03, 9.72102812e-01, 2.06921557e-02],\n",
       "       [2.98928033e-02, 9.53412397e-01, 1.66947997e-02],\n",
       "       [7.51859952e-03, 9.09311256e-01, 8.31701446e-02],\n",
       "       [1.06453394e-02, 9.65411854e-01, 2.39428062e-02],\n",
       "       [8.91387260e-03, 9.49116568e-01, 4.19695590e-02],\n",
       "       [5.73336768e-03, 9.74851600e-01, 1.94150327e-02],\n",
       "       [8.21415088e-02, 9.09172758e-01, 8.68573355e-03],\n",
       "       [8.78478270e-03, 9.54794491e-01, 3.64207268e-02],\n",
       "       [2.64798581e-06, 1.06948145e-03, 9.98927871e-01],\n",
       "       [1.31147595e-04, 3.50881654e-02, 9.64780687e-01],\n",
       "       [2.90366249e-05, 2.90637531e-02, 9.70907210e-01],\n",
       "       [8.33883990e-05, 4.09199449e-02, 9.58996667e-01],\n",
       "       [1.18819035e-05, 6.78394000e-03, 9.93204178e-01],\n",
       "       [2.40528034e-06, 6.27939827e-03, 9.93718196e-01],\n",
       "       [6.03505941e-04, 6.24990974e-02, 9.36897397e-01],\n",
       "       [1.52658172e-05, 2.87514630e-02, 9.71233271e-01],\n",
       "       [1.57141725e-05, 1.86254200e-02, 9.81358866e-01],\n",
       "       [1.95844419e-05, 1.26573423e-02, 9.87323073e-01],\n",
       "       [1.08933459e-03, 2.95298683e-01, 7.03611982e-01],\n",
       "       [1.29214881e-04, 6.47221679e-02, 9.35148617e-01],\n",
       "       [1.14851089e-04, 6.57408005e-02, 9.34144348e-01],\n",
       "       [5.97016356e-05, 1.64518947e-02, 9.83488404e-01],\n",
       "       [2.27387557e-05, 5.06784269e-03, 9.94909419e-01],\n",
       "       [1.36859532e-04, 3.85391807e-02, 9.61323960e-01],\n",
       "       [2.41095526e-04, 1.14861522e-01, 8.84897383e-01],\n",
       "       [1.80711797e-05, 2.40060817e-02, 9.75975847e-01],\n",
       "       [1.65079868e-07, 6.37536312e-04, 9.99362299e-01],\n",
       "       [2.54173655e-04, 1.30088104e-01, 8.69657722e-01],\n",
       "       [4.64796552e-05, 2.67116983e-02, 9.73241822e-01],\n",
       "       [2.25742409e-04, 3.90360083e-02, 9.60738249e-01],\n",
       "       [1.56217252e-06, 5.57203440e-03, 9.94426403e-01],\n",
       "       [8.51442775e-04, 2.89252449e-01, 7.09896108e-01],\n",
       "       [1.09057259e-04, 5.00625075e-02, 9.49828435e-01],\n",
       "       [1.35600310e-04, 1.36081597e-01, 8.63782803e-01],\n",
       "       [1.44190263e-03, 3.77185764e-01, 6.21372333e-01],\n",
       "       [1.60908503e-03, 3.44573797e-01, 6.53817118e-01],\n",
       "       [1.98916075e-05, 1.11312995e-02, 9.88848809e-01],\n",
       "       [3.13691010e-04, 3.38730888e-01, 6.60955421e-01],\n",
       "       [2.11180686e-05, 3.97721856e-02, 9.60206696e-01],\n",
       "       [1.89231924e-04, 2.37061807e-01, 7.62748961e-01],\n",
       "       [1.30441852e-05, 7.18309622e-03, 9.92803860e-01],\n",
       "       [1.24406861e-03, 4.71515313e-01, 5.27240619e-01],\n",
       "       [1.13917104e-04, 6.94305685e-02, 9.30455514e-01],\n",
       "       [1.26703383e-05, 2.29917192e-02, 9.76995610e-01],\n",
       "       [3.78321203e-05, 1.01068187e-02, 9.89855349e-01],\n",
       "       [2.90157941e-04, 1.15512642e-01, 8.84197200e-01],\n",
       "       [2.08024061e-03, 3.79972544e-01, 6.17947215e-01],\n",
       "       [2.80602471e-04, 1.44342635e-01, 8.55376762e-01],\n",
       "       [2.53642639e-05, 1.25458436e-02, 9.87428792e-01],\n",
       "       [4.72866341e-04, 1.84307680e-01, 8.15219454e-01],\n",
       "       [1.31147595e-04, 3.50881654e-02, 9.64780687e-01],\n",
       "       [1.56064776e-05, 9.77719961e-03, 9.90207194e-01],\n",
       "       [2.07093034e-05, 8.91453057e-03, 9.91064760e-01],\n",
       "       [1.72285096e-04, 6.91666482e-02, 9.30661067e-01],\n",
       "       [2.19853888e-04, 9.78726984e-02, 9.01907448e-01],\n",
       "       [4.10218013e-04, 1.48081919e-01, 8.51507863e-01],\n",
       "       [1.25123940e-04, 2.66992456e-02, 9.73175630e-01],\n",
       "       [6.01332345e-04, 1.29937965e-01, 8.69460703e-01]])"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_accuracy = accuracy_score(Y, clf.predict(X))\n",
    "sk_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compare accuracy of custom and sklearn algorithm. \n",
      "\n",
      "   accuracy_custom  accuracy_sk  difference\n",
      "0         0.986667         0.98    0.006667\n"
     ]
    }
   ],
   "source": [
    "print(\"Compare accuracy of custom and sklearn algorithm. \\n\")\n",
    "res_compare_test = pd.DataFrame({'accuracy_custom' : [custom_accuracy], 'accuracy_sk' : [sk_accuracy], 'difference' : [abs(custom_accuracy - sk_accuracy)]})\n",
    "print(res_compare_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "834"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.n_iter_"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
